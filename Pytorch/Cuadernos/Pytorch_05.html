
<!DOCTYPE html>

<html>
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Diferenciación automática con torch.autograd &#8212; Fundamentos de Programación</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="next" title="Optimización con torch" href="Pytorch_06.html" />
    <link rel="prev" title="Transforms" href="Pytorch_04.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="None">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-final-ap.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Fundamentos de Programación</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorial.html">
                    <span style="color:#F72585">Bienvenido(a)</span>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Primeros Pasos
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Inicio/Cuadernos/Consideraciones.html">
   <span style="color:#F72585">
    Conociendo el Libro
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Introducción
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_00.html">
   <span style="color:#F72585">
    Conceptos básicos de programación
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_01.html">
   <span style="color:#F72585">
    Introducción al lenguaje de programación Python
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_02.html">
   <span style="color:#F72585">
    Tipos de Datos Básicos
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_03.html">
   <span style="color:#F72585">
    Operadores aritméticos y lógicos
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_04.html">
   <span style="color:#F72585">
    Estructuras de control
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_05.html">
   <span style="color:#F72585">
    Funciones en Python
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_06.html">
   <span style="color:#F72585">
    Iterables e iteradores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_07.html">
   <span style="color:#F72585">
    Tuplas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_08.html">
   <span style="color:#F72585">
    Listas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_09.html">
   <span style="color:#F72585">
    Diccionarios
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_10.html">
   <span style="color:#F72585">
    Conjuntos
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_11.html">
   <span style="color:#F72585">
    Programación orientada a Objetos en Python
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_12.html">
   <span style="color:#F72585">
    Decoradores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/py_13.html">
   <span style="color:#F72585">
    Patrones para Programación orientada a Objetos en Python
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/Taller_Numpy.html">
   <span style="color:#F72585">
    Taller de numpy
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Python/Cuadernos/Taller_Pandas.html">
   <span style="color:#F72585">
    Taller de manejo de Datos en Pandas
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Pytorch
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="Pytorch_01.html">
   <span style="color:#F72585">
    Primeros pasos con PyTorch
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pytorch_02.html">
   <span style="color:#F72585">
    Tensores en PyTorch
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pytorch_03.html">
   <span style="color:#F72585">
    DataSets y DataLoaders
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pytorch_04.html">
   <span style="color:#F72585">
    Transforms
   </span>
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <span style="color:#F72585">
    Diferenciación automática con torch.autograd
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Pytorch_06.html">
   <span style="color:#F72585">
    Optimización con torch
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  TensorFlow
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../TensorFlow/Cuadernos/Tensorflow-01.html">
   <span style="color:#F72585">
    Inicio Rápido
   </span>
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AprendizajeProfundo/Libro_Fundamentos_Programacion/main?urlpath=tree/Pytorch/Cuadernos/Pytorch_05.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/AprendizajeProfundo/Libro_Fundamentos_Programacion/blob/main/Pytorch/Cuadernos/Pytorch_05.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro_Fundamentos_Programacion"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/issues/new?title=Issue%20on%20page%20%2FPytorch/Cuadernos/Pytorch_05.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/edit/main/Pytorch/Cuadernos/Pytorch_05.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/Pytorch/Cuadernos/Pytorch_05.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-introduccion-span">
   <span style="color:#4361EE">
    Introducción
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-tensores-funciones-y-grafo-computacional-span">
   <span style="color:#4361EE">
    Tensores, funciones y grafo computacional
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-entropia-cruzada-span">
     <span style="color:#4CC9F0">
      Entropía Cruzada
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-calculo-de-gradientes-span">
   <span style="color:#4361EE">
    Cálculo de gradientes
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-deshabilitar-el-seguimiento-de-gradientes-span">
     <span style="color:#4CC9F0">
      Deshabilitar el seguimiento de gradientes
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-mas-sobre-grafos-computacionales-span">
     <span style="color:#4CC9F0">
      Más sobre grafos computacionales
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><span style="color:#F72585">Diferenciación automática con torch.autograd</span></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-introduccion-span">
   <span style="color:#4361EE">
    Introducción
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-tensores-funciones-y-grafo-computacional-span">
   <span style="color:#4361EE">
    Tensores, funciones y grafo computacional
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-entropia-cruzada-span">
     <span style="color:#4CC9F0">
      Entropía Cruzada
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-calculo-de-gradientes-span">
   <span style="color:#4361EE">
    Cálculo de gradientes
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-deshabilitar-el-seguimiento-de-gradientes-span">
     <span style="color:#4CC9F0">
      Deshabilitar el seguimiento de gradientes
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-mas-sobre-grafos-computacionales-span">
     <span style="color:#4CC9F0">
      Más sobre grafos computacionales
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="span-style-color-f72585-diferenciacion-automatica-con-torch-autograd-span">
<h1><span style="color:#F72585">Diferenciación automática con torch.autograd</span><a class="headerlink" href="#span-style-color-f72585-diferenciacion-automatica-con-torch-autograd-span" title="Permalink to this headline">#</a></h1>
<section id="span-style-color-4361ee-introduccion-span">
<h2><span style="color:#4361EE">Introducción</span><a class="headerlink" href="#span-style-color-4361ee-introduccion-span" title="Permalink to this headline">#</a></h2>
<p>Al entrenar redes neuronales, el algoritmo más utilizado es la propagación hacia atrás (<strong>back propagation</strong>). En este algoritmo, los parámetros (pesos del modelo) se ajustan de acuerdo con el gradiente de la función de pérdida con respecto al parámetro dado.</p>
<p>Para calcular esos gradientes, PyTorch tiene un motor de diferenciación incorporado llamado <code class="docutils literal notranslate"><span class="pre">torch.autograd</span></code>. Admite el cálculo automático del gradiente para cualquier gráfo computacional.</p>
</section>
<section id="span-style-color-4361ee-tensores-funciones-y-grafo-computacional-span">
<h2><span style="color:#4361EE">Tensores, funciones y grafo computacional</span><a class="headerlink" href="#span-style-color-4361ee-tensores-funciones-y-grafo-computacional-span" title="Permalink to this headline">#</a></h2>
<p>Considere la red neuronal de una capa más simple, con entrada <span class="math notranslate nohighlight">\(x\)</span>, parámetros <span class="math notranslate nohighlight">\(w\)</span> y <span class="math notranslate nohighlight">\(b\)</span>, y alguna función de pérdida. Se puede definir en PyTorch de la siguiente manera:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">torch</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="mi">5</span><span class="p">)</span> <span class="c1"># entrada</span>
<span class="n">y</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">Tensor</span><span class="p">([</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">0</span><span class="p">])</span> <span class="c1"># etiqueta (valor verdadero)</span>
<span class="n">w</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">5</span><span class="p">,</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span> <span class="c1"># matriz de pesos</span>
<span class="n">b</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">randn</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="n">requires_grad</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span><span class="c1"># bias</span>
<span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span> <span class="c1"># calculo de la capa</span>
<span class="n">loss</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">nn</span><span class="o">.</span><span class="n">functional</span><span class="o">.</span><span class="n">binary_cross_entropy_with_logits</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;x= &#39;</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;y= &#39;</span><span class="p">,</span><span class="n">y</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;w= &#39;</span><span class="p">,</span> <span class="n">w</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b= &#39;</span><span class="p">,</span> <span class="n">b</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;z= &#39;</span><span class="p">,</span> <span class="n">z</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;loss= &#39;</span><span class="p">,</span> <span class="n">loss</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>x=  tensor([1., 1., 1., 1., 1.])
y=  tensor([0., 1., 0.])
w=  tensor([[-0.4924, -1.5046,  0.7841],
        [ 0.8224, -0.2909,  1.5305],
        [ 1.6462,  0.7396,  1.3742],
        [ 0.3657,  0.2611, -0.1246],
        [ 0.9568, -0.4744,  2.3843]], requires_grad=True)
b=  tensor([-0.2576,  0.0902,  0.8894], requires_grad=True)
z=  tensor([ 3.0410, -1.1791,  6.8379], grad_fn=&lt;AddBackward0&gt;)
loss=  tensor(3.7913, grad_fn=&lt;BinaryCrossEntropyWithLogitsBackward0&gt;)
</pre></div>
</div>
</div>
</div>
<section id="span-style-color-4cc9f0-entropia-cruzada-span">
<h3><span style="color:#4CC9F0">Entropía Cruzada</span><a class="headerlink" href="#span-style-color-4cc9f0-entropia-cruzada-span" title="Permalink to this headline">#</a></h3>
<p>Recuerde que si <span class="math notranslate nohighlight">\(p=(p_1, p_2, p_3)\)</span> y <span class="math notranslate nohighlight">\(q=(q_1, q_2, q_3)\)</span> son dos distribuciones de probabilidad, de las cuales una se supone la verdadera, digamos <span class="math notranslate nohighlight">\(q\)</span> y la otra una aproximación, en este caso <span class="math notranslate nohighlight">\(p\)</span>., entonces la entropía cruzada entre <span class="math notranslate nohighlight">\(p\)</span> y <span class="math notranslate nohighlight">\(q\)</span> se define mediante</p>
<div class="math notranslate nohighlight">
\[
\mathfrak{L}(p,q) = - (q_1 \log p_1 + q_2 \log p_2 + q_3 \log p_3)
\]</div>
<p>La entropía cruzada mide que tanto se parece la disribución <span class="math notranslate nohighlight">\(p\)</span> a la distribución <span class="math notranslate nohighlight">\(q\)</span>. En el ejemplo se tiene que <span class="math notranslate nohighlight">\(p = \text{softmax(z)}\)</span> y además <span class="math notranslate nohighlight">\(q=y\)</span>. Observe que por ejemplo <span class="math notranslate nohighlight">\(z_1 = x^T w_1\)</span>, en donde <span class="math notranslate nohighlight">\(w_1\)</span> es la columna 1 de <span class="math notranslate nohighlight">\(w\)</span>. Note que además <span class="math notranslate nohighlight">\(p\)</span> es función de los parámetros <span class="math notranslate nohighlight">\(w\)</span> y <span class="math notranslate nohighlight">\(b\)</span>.</p>
<p>Este código define el siguiente grafo computacional:</p>
<figure>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/comp-graph.png" width="800" height="600"/>
</figure>
<p>Grafo computacional del cálculo descrito arriba.</p>
<p>La propiedad <code class="docutils literal notranslate"><span class="pre">requires_grad</span></code> indica que son variables con respecto a las cuales se desea calcular el gradiente de la función <em>loss</em>.</p>
<p>No es necesario declararlas como tal desde el comienzo. Puede hacerlo luego mediante el método</p>
<ul class="simple">
<li><p>x.requires_grad(True).</p></li>
</ul>
<p>Una función aplicada a tensores de un objeto de la clase <code class="docutils literal notranslate"><span class="pre">Function</span></code>, la cual viene equipada con lo necesario para la diferenciación automática. Una referencia a la función gradiente (back propagation) se almacena en <code class="docutils literal notranslate"><span class="pre">grad_fn</span></code>. Por ejemplo:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Gradient function for z =&#39;</span><span class="p">,</span> <span class="n">z</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;Gradient function for loss =&#39;</span><span class="p">,</span> <span class="n">loss</span><span class="o">.</span><span class="n">grad_fn</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Gradient function for z = &lt;AddBackward0 object at 0x7fc588a1e450&gt;
Gradient function for loss = &lt;BinaryCrossEntropyWithLogitsBackward0 object at 0x7fc588a1ee10&gt;
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="span-style-color-4361ee-calculo-de-gradientes-span">
<h2><span style="color:#4361EE">Cálculo de gradientes</span><a class="headerlink" href="#span-style-color-4361ee-calculo-de-gradientes-span" title="Permalink to this headline">#</a></h2>
<p>Vamos a calcular <span class="math notranslate nohighlight">\(\frac{\partial loss} {\partial w}\)</span> y <span class="math notranslate nohighlight">\(\frac{\partial loss} {\partial b}\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">loss</span><span class="o">.</span><span class="n">backward</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;w.grad= &#39;</span><span class="p">,</span> <span class="n">w</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="s1">&#39;b.grad= &#39;</span><span class="p">,</span> <span class="n">b</span><span class="o">.</span><span class="n">grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>w.grad=  tensor([[ 0.3181, -0.2549,  0.3330],
        [ 0.3181, -0.2549,  0.3330],
        [ 0.3181, -0.2549,  0.3330],
        [ 0.3181, -0.2549,  0.3330],
        [ 0.3181, -0.2549,  0.3330]])
b.grad=  tensor([ 0.3181, -0.2549,  0.3330])
</pre></div>
</div>
</div>
</div>
<p>Admonition</p>
<div class="admonition">
<p class="admonition-title">Nota</p>
<ul class="simple">
<li><p>Solo podemos obtener las propiedades <em>grad</em> para los nodos hoja del grafo computacional, que tienen la propiedad <em>require_grad</em> establecida en <em>True</em>. Para todos los demás nodos de nuestro gráfico, los degradados no estarán disponibles.</p></li>
<li><p>Solo podemos realizar cálculos de gradiente usando hacia atrás una vez en un gráfico dado, por razones de rendimiento. Si necesitamos hacer varias llamadas hacia atrás en el mismo gráfico, debemos pasar <em>retain_graph = True</em> a la llamada hacia atrás.</p></li>
</ul>
</div>
<section id="span-style-color-4cc9f0-deshabilitar-el-seguimiento-de-gradientes-span">
<h3><span style="color:#4CC9F0">Deshabilitar el seguimiento de gradientes</span><a class="headerlink" href="#span-style-color-4cc9f0-deshabilitar-el-seguimiento-de-gradientes-span" title="Permalink to this headline">#</a></h3>
<p>De forma predeterminada,  para todos los tensores con <em>require_grad = True</em> se está rastreando su historial computacional y admiten el cálculo del gradiente. Sin embargo, hay algunos casos en los que no necesitamos hacer eso, por ejemplo, cuando hemos entrenado el modelo y solo queremos aplicarlo a algunos datos de entrada, es decir, solo queremos hacer cálculos reenviados a través de la red. Podemos detener el seguimiento de los cálculos rodeando nuestro código de cálculo con el bloque  <code class="docutils literal notranslate"><span class="pre">torch.no_grad</span> <span class="pre">()</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>

<span class="k">with</span> <span class="n">torch</span><span class="o">.</span><span class="n">no_grad</span><span class="p">():</span>
    <span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
False
</pre></div>
</div>
</div>
</div>
<p>Alternativamente se puede usar el método <code class="docutils literal notranslate"><span class="pre">detach</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">z</span> <span class="o">=</span> <span class="n">torch</span><span class="o">.</span><span class="n">matmul</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">w</span><span class="p">)</span><span class="o">+</span><span class="n">b</span>
<span class="n">z_det</span> <span class="o">=</span> <span class="n">z</span><span class="o">.</span><span class="n">detach</span><span class="p">()</span>
<span class="nb">print</span><span class="p">(</span><span class="n">z_det</span><span class="o">.</span><span class="n">requires_grad</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
<p>Existen motivos por los que quizás desee deshabilitar el seguimiento de gradientes:</p>
<ul class="simple">
<li><p>Para marcar algunos parámetros en su red neuronal como parámetros congelados. Este es un escenario muy común para ajustar una red previamente entrenada (finetunning)</p></li>
<li><p>Para acelerar los cálculos cuando solo está haciendo un paso hacia adelante, porque los cálculos en tensores que no siguen los gradientes serían más eficientes.</p></li>
</ul>
</section>
<section id="span-style-color-4cc9f0-mas-sobre-grafos-computacionales-span">
<h3><span style="color:#4CC9F0">Más sobre grafos computacionales</span><a class="headerlink" href="#span-style-color-4cc9f0-mas-sobre-grafos-computacionales-span" title="Permalink to this headline">#</a></h3>
<p>Conceptualmente, <em>autograd</em> mantiene un registro de datos (tensores) y todas las operaciones ejecutadas (junto con los nuevos tensores resultantes) en un gráfico acíclico dirigido (DAG) que consta de objetos de tipo <em>Function</em>. En este DAG, las hojas son los tensores de entrada, las raíces son los tensores de salida. Al trazar este gráfico desde las raíces hasta las hojas, puede calcular automáticamente los gradientes usando la regla de la cadena.</p>
<p>En un paso hacia adelante (foreward), <em>autograd</em> hace dos cosas simultáneamente:</p>
<ul class="simple">
<li><p>ejecuta la operación solicitada para calcular un tensor resultante</p></li>
<li><p>mantiene la función de gradiente de la operación en el DAG.</p></li>
</ul>
<p>El paso hacia atrás(backward) comienza cuando se llama a <code class="docutils literal notranslate"><span class="pre">.backward()</span></code> en la raíz del DAG. <code class="docutils literal notranslate"><span class="pre">autograd</span></code> entonces:</p>
<ul class="simple">
<li><p>calcula los gradientes de cada <code class="docutils literal notranslate"><span class="pre">.grad_fn</span></code>,</p></li>
<li><p>los acumula en el atributo <code class="docutils literal notranslate"><span class="pre">.grad</span></code> del tensor respectivo</p></li>
<li><p>utilizando la regla de la cadena, se propaga hasta los tensores de las hojas.</p></li>
</ul>
<div class="admonition">
<p class="admonition-title">Nota</p>
<p>Los DAG son dinámicos en PyTorch. Una cosa importante a tener en cuenta es que el gráfico se recrea desde cero; después de cada llamada .backward (), autograd comienza a completar un nuevo grafo. Esto es exactamente lo que le permite utilizar declaraciones de flujo de control en su modelo; puede cambiar la forma, el tamaño y las operaciones en cada iteración si es necesario.</p>
</div>
</section>
</section>
<section id="span-style-color-4361ee-referencias-span">
<h2><span style="color:#4361EE">Referencias</span><a class="headerlink" href="#span-style-color-4361ee-referencias-span" title="Permalink to this headline">#</a></h2>
<ol class="simple">
<li><p>Basado en los <a class="reference external" href="https://pytorch.org/tutorials/">tutoriales de Pytorch</a></p></li>
<li><p><a class="reference external" href="http://library.lol/main/F13E85845AE48D9FD7488FE7630A9FD3">Deep learning for coders with FastAI and Pytorch</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "AprendizajeProfundo/Libro_Fundamentos_Programacion",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Pytorch/Cuadernos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="Pytorch_04.html" title="previous page">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">previous</p>
            <p class="prev-next-title"><span style="color:#F72585">Transforms</span></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Pytorch_06.html" title="next page">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title"><span style="color:#F72585">Optimización con torch</span></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Álvaro Mauricio Montenegro Díaz, Daniel Mauricio Montenegro Reyes<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>