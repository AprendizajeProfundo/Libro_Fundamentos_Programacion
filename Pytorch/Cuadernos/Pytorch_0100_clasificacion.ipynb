{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3e57f3e1-d4f2-4329-8359-0a0370026c28",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\"><center>Introducción a la Programación Orientada a Objetos (POO)</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcc462c6-8c5b-4b21-8c85-7f1dbd7d58d8",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/trainer.png\" width=\"800\" height=\"400\" align=\"center\"/>\n",
    "</center>\n",
    "</figure>\n",
    "\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8b46a8c-2e09-433b-9c33-55ec094b0af7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd5170e0-66b6-4579-8c09-feef0b8ecdfa",
   "metadata": {},
   "source": [
    "Python es un lenguaje de programación orientado a objetos. **Todo** en Python es un objeto, con sus propiedades y métodos.\n",
    "\n",
    "En esta sesión crearemos una red neuronal, usando `el paradigma programación orientado a objetos`, y crearemos un entrenador para entrenar la red de tal manera que prediga el tipo de prenda del conjunto de datos mnist-fashion.\n",
    "\n",
    "El conjunto de datos mnist-fashion, puede cargarse directamente del conjunto de ejemplos de [Pytorch](https://pytorch.org/). En realidad, este conjunto de datos muy famoso en el área de la inteligencia artificial moderna puede descargarse de varios sitios. Por facilidad en esta lección lo descargamos directamente de Pytorch.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1003eb86-a1f3-41ea-8541-2c410d97499d",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Instalar Pytorch </span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a74918d-e40d-4cc0-9b2f-310361f28f50",
   "metadata": {},
   "source": [
    "En consola ejecute el siguiente comando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f9ccff-bd13-46fb-b3b6-ec41f8c5d124",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conda install -c pytorch pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "085cb8ca-8a54-4fe7-882f-c04182a65e64",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:blue\">Trabajando con datos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65627347-456e-42fb-8041-96f1ac55dc45",
   "metadata": {},
   "source": [
    "PyTorch tiene dos primitivas para trabajar con datos: `torch.utils.data.DataLoader` y `torch.utils.data.Dataset`. *Dataset* almacena las muestras y sus etiquetas correspondientes, y *DataLoader* envuelve un iterable alrededor de *Dataset*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5e3bcdc-fb2e-414e-9e5c-fd76300f94b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "#from torch.nn import Flatten, Sequential, Linear, ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d360b58-14b2-4541-830d-ff2fabadbc67",
   "metadata": {},
   "source": [
    "PyTorch ofrece bibliotecas específicas de dominio como `TorchText`, `TorchVision` y `TorchAudio`, todas las cuales incluyen conjuntos de datos. Para este tutorial, usaremos un conjunto de datos de `TorchVision`.\n",
    "\n",
    "El módulo `torchvision.datasets` contiene objetos de conjunto de datos para muchos datos de visión del mundo real como CIFAR, COCO ([lista completa aquí](https://pytorch.org/vision/stable/datasets.html)). En este tutorial, usamos el conjunto de datos FashionMNIST. Cada conjunto de datos de TorchVision incluye dos argumentos: *transform* y *target_transform* para modificar las muestras y las etiquetas respectivamente.\n",
    "\n",
    "En el siguiente fragmento de código se leen los datos para entrenamiento y test. Si aún no se han bajado los datos, Pytorch lo hace por esta única ocasión. La próxima vez los leerá de la carpeta interna 'data'. El parámetro *transform* permite convertir los datos a un formato específico. En este caso a tensores de Torch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660fa16a-0cc7-4053-bcb0-667de5125b26",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Crea un dataset con los datos de FashionMNIST</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117775fb-d240-4c07-be77-1e7720a8781a",
   "metadata": {},
   "source": [
    "Si es necesario baja los datos desde el origen de Pythorch y los dja en una carpeta interna (root). Si los datos ya existen en esa carpeta, no los baja de nuevo. Primero baja los datos de entrenamiento y luego los de validación.\n",
    "\n",
    "Se usa la transformación `ToTensor` para transformar los datos leídos en tensores de Torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25943a2-0c10-4896-93db-3900d78f6a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baja los datos de entrenamiento de open datasets.\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "# Baja los datos test data de open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d113ced6-60b7-4316-920b-b3f7bfa327ef",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Una primera imagen de los datos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da804267-e16f-47c0-b51a-900fc6b409f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};\n",
    "fig = plt.figure(figsize=(8,8));\n",
    "columns = 4;\n",
    "rows = 5;\n",
    "for i in range(1, columns*rows +1):\n",
    "    img_xy = np.random.randint(len(training_data));\n",
    "    img = training_data[img_xy][0][0,:,:]\n",
    "    fig.add_subplot(rows, columns, i)\n",
    "    plt.title(labels_map[training_data[img_xy][1]])\n",
    "    plt.axis('off')\n",
    "    plt.imshow(img, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d5f1c7-1f10-498b-b8c5-561f53f13821",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Envuelve el dataset en un DataLoader</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee36f6b-5556-4ac5-b436-a76120a146ab",
   "metadata": {},
   "source": [
    "Pasamos el *Dataset* como un parámetro para `DataLoader`\n",
    "Esto crea un iterable sobre nuestro conjunto de datos y admite procesamiento por lotes, muestreo, barajado y carga de datos multiproceso automáticos. Aquí definimos un tamaño de lote de 32, es decir, cada elemento en el cargador de datos iterable devolverá un lote de 64 imágenes con sus etiquetas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf16e3f8-ee38-4e63-92b1-ff1a99aed771",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "\n",
    "#crea data loaders\n",
    "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('X[N, C, H, W]: ', X.shape)\n",
    "    print('Shape of y: ', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3f2e10-6632-4427-b426-f9824c3ed658",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Creación de datasets personalizados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0614ef-54c0-41e2-97cc-d4a74bb68606",
   "metadata": {},
   "source": [
    "Si requiere crear un dataset personalizado para su conjunto de datos, puede consultar [aquí](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eea5f08-a1f1-4e91-b04f-7a64769631b1",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Programación Orientada a Objetos</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e35b5b1-be33-4b32-ae71-224f6579c1f4",
   "metadata": {},
   "source": [
    "La programación orientada a objetos (POO) es el paradigma de programación mas utilizado modernamente para el desarrollo de aplicaciones. Python, R, C++, Java  y la mayor parte de los lenguajes modernos son orientados a objetos.\n",
    "\n",
    "Los modelos de la inteligencia artificial más potentes por lo general se desarrollan con POO. Pytorch es orientado a objetos y siempre sugiere trabajar de esa forma. A continuación hacemos una breve introducción de los concepto básicos mediante un ejemplo en el cual crearemos y entrenaremos un a red neuronal que se capaz de clasificar imágenes de FashionMNIST."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5618f651-22a1-4722-9230-42977e3cfa13",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Clases e instancias de clase (objetos)</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b2d33-e23b-4288-b77e-fe676c423cf3",
   "metadata": {},
   "source": [
    "En la programación orientada a objetos se diseñan piezas de código que llamamos objetos que interactúan entre si.\n",
    "Para empezar, debemos diferenciar entre clase e instancia de clase.\n",
    "\n",
    "Por clase se entiende el plano o plantilla de los objetos. Las instancia de clase son son objetos propiamente dichos. Esto significa que se diseña e implementa una clase y se instancian objetos de esa clase.\n",
    "\n",
    "Las dos imágenes siguientes tomadas de Wikipedia ilustra la diferencia entre clase (plano) e instancias de clase (los objetos). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6746f7b-d3ab-4359-8bf6-7ed2059c4545",
   "metadata": {},
   "source": [
    "**Idealización de un clase**\n",
    "\n",
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/plano_circuito_Musical_Organ.jpeg\"  width=\"400\" height=\"400\" align=\"center\"/> \n",
    "</figure>\n",
    "\n",
    "El diagrama de circuito del chip de sonido Texas Instruments SN76477. Fuente <a href=\"https://commons.wikimedia.org/wiki/File:76477_Musical_Organ.JPG\">Technogeezer</a>, <a href=\"https://creativecommons.org/licenses/by-sa/3.0\">CC BY-SA 3.0</a>, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30bb1a9-6910-444d-a0ca-982a9e07d89a",
   "metadata": {},
   "source": [
    "**Instancias de clase: objetos**\n",
    "\n",
    "<figure> \n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/chipTesasIntruments.jpg\"  width=\"400\" height=\"200\" align=\"left\"/> \n",
    "</figure>\n",
    "<figure> \n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/chipTesasIntruments.jpg\"  width=\"400\" height=\"200\" align=\"right\"/> \n",
    "</figure>\n",
    "\n",
    "\n",
    "Chip de sonido Texas Instruments SN76477. Fuente <a href=\"https://commons.wikimedia.org/wiki/File:Sn76477.jpg\">Leomil72</a>, Public domain, via Wikimedia Commons"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34189917-2db0-43d0-92f9-aeeba5da9b7a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Ejemplo de clases e instancias de clase</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "670e7b44-60e8-4070-adc5-5dddf7e61e57",
   "metadata": {},
   "source": [
    "En el siguiente ejemplo creamos dos instancias de la clase `NeuralNetwork`.\n",
    "\n",
    "Para crear una clase, usa el la palabra clave```class:```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bbed38b-1f74-4e9c-91c5-3a954b716e6f",
   "metadata": {},
   "source": [
    "Creemos una clase que no haga nada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b36c79-c1af-4e15-b0cf-2ef0bc6a2b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d667e80-f304-4990-8d2c-0fc693e90e73",
   "metadata": {},
   "source": [
    "A continuación creamos dos instancias de esta clase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3669162b-0d22-4783-993d-c79193aa9efc",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo_1 = NeuralNetwork()\n",
    "modelo_2 = NeuralNetwork()\n",
    "print(modelo_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e010371a-7829-49c0-be80-cfb1653a7b76",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Herencia</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16d92f3f-b45c-433a-b8c9-7f4563a71e62",
   "metadata": {},
   "source": [
    "Es posible derivar una clase de otra, para disponer de todo el contenido de lace base. Este proceso se conice como subclassing y la técnica como herencia. \n",
    "\n",
    "En el siguiente fragmento derivamos la clase `NeuralNetwork` de la clase base `nn.Module`, la cual contiene toda la infraestructura básica pra implementar una red neuronal. Esto permite concentrarse en el modleos y no en los detalles de implementación básica."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "060346cf-7f9d-4231-b29c-978abaf063e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bdf5d6e-90a2-4fb2-9fb6-40b67e5c02a8",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\"> Métodos y propiedades </span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0d7495-4f18-4b79-b904-b2d9424f1b65",
   "metadata": {},
   "source": [
    "Una clase útil debe tener datos sobre los cuales trabaja. Estos se denominan `propiedades`. Los `métodos` son la funciones internas de la clase que hacen tareas específicas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72891112-7aed-4236-83ce-b5e996eef877",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Constructor \\_\\_init\\_\\_()</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af0a0c96-f1ac-43c5-8980-cfc9cf1ac950",
   "metadata": {},
   "source": [
    "Una función dentro de una clase de llama **método**. \\_\\_init\\_\\_ es el abreviado de **initialization** (inicialización). También se le conoce como el **constructor**.\n",
    "\n",
    "**Note los dos guiones bajos antes y después de init**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f963d125-7106-4002-9231-5255cd9fadf0",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Creando una red neuronal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e764b5-ebe7-474c-869d-04c1a984d93c",
   "metadata": {},
   "source": [
    "Para definir una red neuronal en PyTorch, creamos una clase que hereda de nn.Module. Definimos las capas de la red en la función __init__ y especificamos cómo pasarán los datos a través de la red en la función de reenvío. Para acelerar las operaciones en la red neuronal, lo trasladamos a la GPU si está disponible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce557377-b17a-4149-9b63-bc22f6fee8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Flatten, Sequential, Linear, ReLU\n",
    "\n",
    "# define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        #llama al cosntructor de la clase base\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # define las capas que usará en la construcción del modelo\n",
    "        self.flatten = Flatten()\n",
    "        self.linear_relu_stack = Sequential(\n",
    "            Linear(28*28, 512),\n",
    "            ReLU(),\n",
    "            Linear(512, 512),\n",
    "            ReLU(),\n",
    "            Linear(512, 10),\n",
    "            ReLU()\n",
    "        )\n",
    "        \n",
    "    # El método forward es la que define la estructura de la red\n",
    "    # en este ejemplo aceptamos solo una entrada, pero si lo desea,\n",
    "    # siéntase libre de usar más\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "# instancia un objeto\n",
    "model = NeuralNetwork()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac80578",
   "metadata": {},
   "source": [
    "```{admonition} Nota\n",
    ":class: \n",
    "Cuando se invoca model, automáticamente se ejecuta la función *\\_\\_call\\_\\_* de la clase. En Pytorch la clase `nn.Module` de la cual derivamos  nuestra clase, llama internamente a la función *forward*, que nosotros debemos sobrecargar (escribir para definir nuestro modelo), como puede verificar [aquí](https://github.com/pytorch/pytorch/blob/472be69a736c0b2aece4883be9f8b18e2f3dfbbd/torch/nn/modules/module.py#L487).\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4d1a339-338e-4da1-80c1-607623f1fb4e",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Entrenamiento de una red neuronal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd94bdd4-4a1d-4e6a-8367-a62fbf4de73a",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "\n",
    "<figure> \n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/trainer.png\"  width=\"800\" height=\"400\" align=\"center\"/> \n",
    "</figure>\n",
    "Entrenamiento de una red neuronal. Modelo de objetos.\n",
    "\n",
    "Fuente Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cd2e8-e343-4fbb-a2f1-0a4b3e4a0ff7",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase NeuralNetwork</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fc3c68f-193f-41d7-b0ec-cdf7a0ec9657",
   "metadata": {},
   "source": [
    "Esta clase define el modelo de red neuronal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ebd6a8-f4d4-4b8e-b8db-ab79400f2eec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "from torch.nn import Flatten, Sequential, Linear, ReLU\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        \n",
    "        # llama constructor de la clase base\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        \n",
    "        # define capas de la red\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "print(NeuralNetwork())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0a448e-ce81-43fa-8192-e6946617552f",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase Trainer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8bb41e-cf71-4f23-87d8-a3ee002521f5",
   "metadata": {},
   "source": [
    "Esta clase es diseñada para controlar el proceso de entrenamiento. Antes de crear un objeto de tipo dataset, asegúrese de tener disponible los siguiente objetos\n",
    "\n",
    "1. Un modelo.\n",
    "1. Un optimizador configurado para el modelo\n",
    "1. Una función de pérdida adecuada para el modelo\n",
    "\n",
    "Opcionalmente puede de un objeto SummaryWriter de Tensorboard y el path para almacenar los modelos.\n",
    "\n",
    "Para ejecutar el método `fit` se requiere disponer de los objetos de datos para entrenamiento y validación. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe0460da-49a7-4777-bf51-0869b05e0dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "from torch.nn.functional import softmax\n",
    "\n",
    "class Trainer:\n",
    "    def __init__(self, model, loss_fn, optimizer, metrics=None,\n",
    "                 metric_names=None,\n",
    "                 writer=None, path_to_save='',\n",
    "                 learning_rate = 1e-3,\n",
    "                 batch_size = 64,\n",
    "                 epochs = 5, n_report= 1000):\n",
    "        #################################\n",
    "        # propiedades de la clase Trainer\n",
    "        #################################\n",
    "        # red neuronal\n",
    "        self.model = model\n",
    "        # función de pérdida\n",
    "        self.loss_fn = loss_fn\n",
    "        # optimizador\n",
    "        self.optimizer = optimizer\n",
    "        # métricas\n",
    "        self.metrics_train = metrics\n",
    "        self.metrics_valid = self.metrics_train.copy()\n",
    "        self.metric_names = metric_names\n",
    "        \n",
    "        # writer de tensorboard \n",
    "        self.writer = writer\n",
    "        \n",
    "        # hiperparámetros\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs\n",
    "        self.n_report = n_report\n",
    "        \n",
    "        # path para almacenar los modelos\n",
    "        self.path_to_save = path_to_save\n",
    "        # path al mejor modelo encontrado\n",
    "        self.best_model = None\n",
    "        \n",
    "        # datos: se cargan desde la función fit\n",
    "        # datos de entrenamiento\n",
    "        self.training_loader = None\n",
    "        # datos de validación\n",
    "        self.validation_loader = None\n",
    "     \n",
    "    ##############################\n",
    "    #  Métodos de la clase Trainer\n",
    "    ##############################\n",
    "    # setters              \n",
    "    def set_model(self, model):\n",
    "        self.model = model\n",
    "    \n",
    "    def set_loss(self, loss):\n",
    "        self.loss = loss\n",
    "        \n",
    "    def set_optimizer(self, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "    def set_writer(self, writer):\n",
    "        self.writer =  writer\n",
    "    # getters\n",
    "    def get_model(self):\n",
    "        return self.model\n",
    "    \n",
    "    \n",
    "    def set_hiperparameters(self,\n",
    "                 learning_rate = 1e-3,\n",
    "                 batch_size = 64,\n",
    "                 epochs = 5):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.batch_size = batch_size\n",
    "        self.epochs = epochs        \n",
    "    \n",
    "    #####################################\n",
    "    # métodos básicos para entrenamiento\n",
    "    #####################################\n",
    "    # paso de entrenamiento\n",
    "    def _train_one_epoch_(self, epoch_index):\n",
    "        \"\"\"\n",
    "        corre un paso de entrenamiento\n",
    "        :params\n",
    "        :epoch_index: índice de la época\n",
    "        :n_report: cada cuantas iteraciones reportar en pantalla\n",
    "        \"\"\"\n",
    "        running_loss = 0.\n",
    "        last_loss = 0.\n",
    "        # Aquí, usamos enumerate(training_loader) en lugar de\n",
    "        # iter(training_loader) para que podamos rastrear el lote\n",
    "        # indexar y hacer algunos informes dentro de la época\n",
    "        for i, data in enumerate(self.training_loader):\n",
    "            # Cada instancia de datos contiene parejas  input + label \n",
    "            inputs, labels = data\n",
    "\n",
    "            # backpropagation\n",
    "            # por defecto el cálculo del gradiente es acumulativo\n",
    "            # comienza colocando el gradiente en cero\n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Hace la predicción para este lote (batch)\n",
    "            outputs = self.model(inputs)\n",
    "            predicts = softmax(outputs, dim=-1)\n",
    "\n",
    "            # Calcula la pérdida y sus gradientes\n",
    "            loss = self.loss_fn(outputs, labels)\n",
    "            loss.backward()\n",
    "\n",
    "            # Ajusta los pesos del modelo \n",
    "            # w{i+1} = w{i} + learning_rate * grad(loss)\n",
    "            self.optimizer.step()\n",
    "\n",
    "            # Recolecta  datos y los reporta\n",
    "            # pérdida\n",
    "            running_loss += loss.item()\n",
    "            # metricas\n",
    "            running_metrics = self._metric_step_(predicts, labels, metric_compute=False, \n",
    "                                          validation=False)\n",
    "            \n",
    "            if i % self.n_report == (self.n_report-1):\n",
    "                # pérdida\n",
    "                last_loss = running_loss / self.n_report # pérdida promedio por lote(batch)\n",
    "                running_loss = 0.\n",
    "                # métricas\n",
    "                last_metrics = self._metric_step_(None, None, metric_compute=True, \n",
    "                                          validation=False)\n",
    "                \n",
    "                # imprime pérdida del lote\n",
    "                print('Pérdida en el lote {} : {}'.format(i + 1, last_loss))\n",
    "                \n",
    "                # imprime métricas del lote\n",
    "                print_m = ''\n",
    "                for j in range(len(metrics)):\n",
    "                    print_m += self.metric_names[j] + ': ' + str(last_metrics[j]) + ' '\n",
    "                print('Métricas en el lote {} : {}'.format(i + 1, print_m))\n",
    "                \n",
    "                # escribe en el writer\n",
    "                if self.writer is not None:\n",
    "                    tb_x = epoch_index * len(training_loader) + i + 1\n",
    "                    # pérdida\n",
    "                    self.writer.add_scalar('Pérdida/Entrenamiento', last_loss, tb_x)\n",
    "                    # métricas\n",
    "                    for i in range(len(last_metric)):\n",
    "                        self.writer.add_scalar(self.metric.names[i] + '/Entrenamiento', \n",
    "                                               last_metrics[i], tb_x)\n",
    "                        \n",
    "                \n",
    "                \n",
    "    def _validation_step_(self, validation=True):\n",
    "        \"\"\"\n",
    "        corre un paso de validación\n",
    "        :params: validation=True; toma los datos de validación\n",
    "        :        sino toda los datos de entrenamiento\n",
    "        \"\"\"\n",
    "        \n",
    "        if validation:\n",
    "            data_loader = self.validation_loader\n",
    "        else:\n",
    "            data_loader = self.training_loader\n",
    "        \n",
    "        # Pérdida\n",
    "        running_vloss = 0.0   \n",
    "        for i, vdata in enumerate(data_loader):\n",
    "            vinputs, vlabels = vdata\n",
    "            voutputs = self.model(vinputs)\n",
    "            vpredicts = softmax(voutputs,dim=-1)\n",
    "            vloss = self.loss_fn(voutputs, vlabels)\n",
    "            \n",
    "            running_vloss += vloss\n",
    "            _  = self._metric_step_(vpredicts, vlabels, \n",
    "                            metric_compute=False, validation= validation)\n",
    "\n",
    "        avg_vloss = running_vloss / (i + 1)\n",
    "        v_metrics =   self._metric_step_(None, None, metric_compute=True, \n",
    "                                          validation= validation)\n",
    "        \n",
    "        return avg_vloss, v_metrics\n",
    "        \n",
    "    def _metric_step_(self, predicts, labels, metric_compute=False, validation=False):\n",
    "        \"\"\"\n",
    "        actualiza y calcula las métricas\n",
    "        \"\"\"            \n",
    "                \n",
    "        if validation:\n",
    "            metrics = self.metrics_valid\n",
    "        else:\n",
    "            metrics = self.metrics_train\n",
    "        \n",
    "        if predicts is not None and labels is not None:\n",
    "            for i, metric in enumerate(metrics):\n",
    "                metrics[i].update(predicts, labels)\n",
    "        \n",
    "        if metric_compute:\n",
    "            values = [metric.compute().item() for metric in metrics]\n",
    "            for metric in metrics:\n",
    "                metric.reset() \n",
    "        else:\n",
    "            values = [metric(predicts, labels).item() for metric in metrics]\n",
    "    \n",
    "        return values\n",
    "      \n",
    "    \n",
    "    # ciclo de entrenamiento\n",
    "    def _train_loop_(self):\n",
    "        # registra marca  de tiempo\n",
    "        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n",
    "        # contador de epochs\n",
    "        epoch_number = 0\n",
    "\n",
    "        # Inicializa la mejor pérdida en un valor muy grande\n",
    "        # el propósito es mejorar esta mejor pérdida\n",
    "        best_vloss = 1_000_000.\n",
    "        \n",
    "         \n",
    "        # ciclo de entrenamiento\n",
    "        for epoch in range(self.epochs):\n",
    "            print('época {}:'.format(epoch_number + 1))\n",
    "            \n",
    "            # paso de entrenamiento\n",
    "            # coloca en modelo en modo entrenamiento \n",
    "            model.train(True)\n",
    "            # lanza un paso de entrenamiento\n",
    "            self._train_one_epoch_(epoch_number)\n",
    "\n",
    "            # paso de validación \n",
    "            # coloca el modelo en modo inferencia\n",
    "            self.model.train(False)\n",
    "            \n",
    "            # lanza un paso de validación\n",
    "            e_loss, e_metrics = self._validation_step_(validation=False)\n",
    "            v_loss, v_metrics = self._validation_step_(validation=True)\n",
    "            \n",
    "            # imprime pérdida dela época\n",
    "            print('Pérdida entrenamiento: {}, validación {}'.format(e_loss, v_loss))\n",
    "            \n",
    "            # imprime métricas del lote la época\n",
    "            print_m_e = ''\n",
    "            for i in range(len(e_metrics)):\n",
    "                print_m_e += self.metric_names[i] + ': ' + str(e_metrics[i]) + ' '\n",
    "            print_m_v = ''\n",
    "            for i in range(len(v_metrics)):\n",
    "                print_m_v += self.metric_names[i] + ': ' + str(v_metrics[i]) + ' '     \n",
    "            print('Métricas en entrenamiento : {}, validación {} '.format(print_m_e, print_m_v))\n",
    "\n",
    "            # Registra (log) la pérdida actual promedio  por lote (batch)\n",
    "            # para entrenamiento y validación\n",
    "            if self.writer is not None:\n",
    "                # pérdida\n",
    "                self.writer.add_scalars('Pérdida entrenamiento v.s. Pérdida validación',\n",
    "                                { 'Entrenamiento' : e_loss, 'Validación' : e_vloss },\n",
    "                                epoch_number + 1)\n",
    "                \n",
    "                # métricas\n",
    "                for i in range(len(e_metrics)):  \n",
    "                    self.writer.add_scalars(self.metric.names[i] + 'entrenamiento v.s. validación',\n",
    "                                { 'Entrenamiento' : e_metrics[i], 'Validación' : v_metrics[i] },\n",
    "                                epoch_number + 1)\n",
    "                  \n",
    "                self.writer.flush()\n",
    "\n",
    "            # Realice un seguimiento del mejor rendimiento y guarda el estado del modelo\n",
    "            if  v_loss < best_vloss:\n",
    "                best_vloss = v_loss\n",
    "                model_path = self.path_to_save + 'model_{}_{}'.format(timestamp, epoch_number)\n",
    "                torch.save(model.state_dict(), model_path)\n",
    "                self.path_best_model = model_path\n",
    "\n",
    "            epoch_number += 1 \n",
    "        \"\"\"\n",
    "        calculo final de pérdida y métric no se requiere\n",
    "        \"\"\"\n",
    "       \n",
    "                    \n",
    "            \n",
    "    def fit(self, train_data, val_data, epochs=None, writer=None, best_loss=True):\n",
    "        if writer is not None:\n",
    "            self.writer = writer\n",
    "        if epochs is not None:\n",
    "            self.epochs = epochs\n",
    "       # datos de entrenamiento\n",
    "        self.training_loader = train_data\n",
    "        # datos de validación\n",
    "        self.validation_loader = val_data\n",
    "        \n",
    "        # lanza loop de entrenamiento\n",
    "        self._train_loop_()\n",
    "        # carga al modelo los pesos con mejor pérdida\n",
    "        if best_loss:\n",
    "            self.model.load_state_dict(torch.load(self.path_best_model))\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40238690-7941-442a-93f5-c2bb101f46d4",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase Data</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c47940-f568-4a5b-a697-f95302ddcb98",
   "metadata": {},
   "source": [
    "Clase contenedora de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed53844a-5b4b-4ea2-95e1-a090f8427697",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "class Data():\n",
    "    \"\"\"\n",
    "    Esta clase recibe un dataset, y lo envuelve en un dataloader\n",
    "    \n",
    "    :\n",
    "    se definen getter y setter para la propiedad data\n",
    "    \"\"\"\n",
    "    def __init__(self, dataset=None, batch_size=64, shuffle=True):\n",
    "        \"\"\"\n",
    "        :params: dataset: opcional dataset incial inicial\n",
    "        :batch_size: tamaño de los lotes de datos para el Dataloader\n",
    "        :shuffle: True= mezclar los datos aleatoriamente (para entranamiento)\n",
    "        \"\"\"     \n",
    "        self.dataset = dataset\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self._data = DataLoader(dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "    \n",
    "    # getter\n",
    "    def get_data(self):\n",
    "        return self._data\n",
    "    \n",
    "    # setter\n",
    "    def set_data(self, dataset):\n",
    "        self._dataset = dataset\n",
    "        self._data = DataLoader(self._dataset, batch_size=self.batch_size, shuffle=self.shuffle)\n",
    "    \n",
    "    # crea la propiedad data\n",
    "    data = property(get_data, set_data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self._data)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0fda56c-e5b3-4a79-804e-9c5be4cc1d3e",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase Drawer</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb92fb0-d347-48dd-9f40-95bbd1feece0",
   "metadata": {},
   "source": [
    "Esta es una clase auxiliar que usaremos para desplegar ejemplos de los objetos en pantalla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82624b8f-b232-40e5-b646-a6014110d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Drawer:\n",
    "    \"\"\"\n",
    "    Clase utilitaria para deplegar imágenes en línea\n",
    "    asumimos que los datos no están listos para ser desplegados\n",
    "    Por ejemplo si tiene los datos normalizados revierta el proceso\n",
    "    \n",
    "    \"\"\"    \n",
    "    def __init__(self, dataset, label_names, rows=5, columns=4, figsize=(8,8)):\n",
    "        \n",
    "        \"\"\"\n",
    "        :params\n",
    "        : data_set: dtaset de datos\n",
    "        : label_names: nombres asociados a las  la etiquetas de los datos\n",
    "        : rows: número de filas e¿del gráfico\n",
    "        : columns: núemro de columnas del gráfico\n",
    "        \"\"\"\n",
    "        self.dataset = dataset\n",
    "        self.label_names = label_names\n",
    "        self.rows = rows\n",
    "        self.columns = columns\n",
    "        self.figsize = figsize\n",
    "    \n",
    "    def plot(self):\n",
    "        fig = plt.figure(figsize=self.figsize);\n",
    "        \n",
    "        for i in range(1, self.columns * self.rows +1):\n",
    "            img_xy = np.random.randint(len(self.dataset));\n",
    "            img = self.dataset[img_xy][0][0,:,:]\n",
    "            fig.add_subplot(self.rows, self.columns, i)\n",
    "            plt.title(labels_map[self.dataset[img_xy][1]])\n",
    "            plt.axis('off')\n",
    "            plt.imshow(img, cmap='gray')\n",
    "        plt.show()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ccf6f7-be4d-4b70-b2e0-335e177e412a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Crea los objetos para el entrenamiento</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60604f75-ed8c-42b8-89ce-b3e1c8fd47b4",
   "metadata": {},
   "source": [
    "Esta parte depende de los datos del problema. Para crear dataset personalizado consulte [aquí](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f956bb2e-7909-4421-9fad-38a0c5baa7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "from torch import nn\n",
    "from torch.nn import Flatten, Sequential, Linear, ReLU\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "from torchmetrics import Accuracy\n",
    "\n",
    "# Prepara los datos\n",
    "## Transformaciones para los datos\n",
    "\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transform\n",
    ")\n",
    "\n",
    "# Sube los datos a objetos Data, que son\n",
    "# contenedores del dataset y DataLoader\n",
    "\n",
    "train = Data(train_data, batch_size=32)\n",
    "validation = Data(test_data, batch_size=32, shuffle=False)\n",
    "\n",
    "# Crea el modelo\n",
    "# Obtiene gpu o cpu device para el entrenamiento\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print('using {} device'.format(device))\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# Optimizador\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "# Función de pérdida\n",
    "loss_fn = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# initializa métrica\n",
    "# se espera una lista de métricas\n",
    "metrics = [Accuracy()] # accuracy\n",
    "# pasar nombre en español de la métrica\n",
    "# TODO hacer esto con una clase traductora\n",
    "metric_names = ['Exactitud']\n",
    "# path para almacenar los pesos de los mejores modelos\n",
    "path_to_save = '../Modelos/'\n",
    "\n",
    "# Trainer\n",
    "trainer = Trainer(model=model, loss_fn=loss_fn,  \n",
    "                  optimizer=optimizer, metrics=metrics, \n",
    "                  metric_names = metric_names,\n",
    "                  n_report=375, path_to_save= path_to_save )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3674324-0e37-47e7-aef0-d71dd4aa69dc",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Una mirada a las imágenes</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbaf4a0f-f2dd-4eac-886a-9b4691dcd659",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_map = {0 : 'T-Shirt', 1 : 'Trouser', 2 : 'Pullover', 3 : 'Dress', 4 : 'Coat', 5 : 'Sandal', 6 : 'Shirt',\n",
    "              7 : 'Sneaker', 8 : 'Bag', 9 : 'Ankle Boot'};\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "drawer = Drawer(dataset=test_data, label_names=labels_map)\n",
    "drawer.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cec5603-1f8f-4005-a4e5-93e308919c92",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc57479-414f-4cf1-8edf-8d9af45d57f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.fit(train.data, validation.data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46325c06-deff-453d-af23-efd4c5d2e297",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Puesta en producción</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d29356-ca7a-4ab8-81b5-0dcb509b101a",
   "metadata": {},
   "source": [
    "Nuestro modelo está entrenado (con una exactitud del 64\\%). Por supuesto podemos mejorar mucho esta exactitud, pero de momento lo dejaremos así. Si se pregunta porque tiene una exactitud tan baja, tenga en cuenta que hemos usado un perceptron muy simple. Para este caso, un modelo convolucional irá mucho mejor.\n",
    "\n",
    "\n",
    "Vamos a recuperar el mejor modelo obtenido. Los puntos de chequeo los tenemos guardados, por lo que será muy fácil saber cuál es el mejor modelo. Lo cargaremos a una red nueva y haremos algunas predicciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983cfdb6-5ea6-43be-bf7f-fb35746e23c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import softmax\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model, checkpoint):\n",
    "        self.model = model\n",
    "        self.model.load_state_dict(torch.load(checkpoint))\n",
    "    \n",
    "    def predict(self, data):\n",
    "        out = self.model(data)\n",
    "        pred = softmax(out, dim=-1)\n",
    "        return pred.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d473597-a6e7-4359-90f5-ea5adca1b747",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = '../Modelos/' + 'model_20220218_150208_4'\n",
    "p = Predictor(NeuralNetwork(), checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a39672b5-6ed4-41ff-b5f4-e7efd8142435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Baja los datos test data de open datasets.\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "batch_size = 10\n",
    "\n",
    "#crea un data loader\n",
    "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
    "\n",
    "for X, y in test_dataloader:\n",
    "    print('X[N, C, H, W]: ', X.shape)\n",
    "    print('Shape of y: ', y.shape, y.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e8835b5-0354-463d-98bb-5d6a351e8f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "for X, y in test_dataloader:\n",
    "    pred = p.predict(X)\n",
    "    for i in range(pred.shape[0]):\n",
    "        print ('label: {}, prediction: {}'.format(y[i].item(), np.round(pred[i],3)))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebcea22-0cb4-4a55-be58-1ccee2212eea",
   "metadata": {},
   "source": [
    "**¡Eso es todo!**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "544ed5af-31ef-412a-b5af-42fd16f7ee52",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Referencias</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "933c8926-eaee-431d-9f95-f183ca09c2f7",
   "metadata": {},
   "source": [
    "1. [Alvaro Montenegro y Daniel Montenegro, Inteligencia Artificial y Aprendizaje Profundo, 2021](https://github.com/AprendizajeProfundo/Diplomado)\n",
    "1. [Alvaro Montenegro, Daniel Montenegro y Oleg Jarma, Inteligencia Artificial y Aprendizaje Profundo Avanzado, 2022](https://github.com/AprendizajeProfundo/Diplomado-Avanzado)\n",
    "1. [Tutoriales de Pytorch](https://pytorch.org/tutorials/)\n",
    "1. [Deep learning for coders with FastAI and Pytorch](http://library.lol/main/F13E85845AE48D9FD7488FE7630A9FD3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "f08154012ddadd8e950e6e9e035c7a7b32c136e7647e9b7c77e02eb723a8bedb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
