{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "98b851f7-c675-4a2a-8932-59bf23db8edb",
   "metadata": {},
   "source": [
    "# <span style=\"color:#F72585\"><center>Pytorch-lightning</center></span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacf25ed-8d82-41b0-8a83-480750b0b427",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<center>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Alejandria/main/Pytorch/Imagenes/Pytorch_ligthning_logo.png\" width=\"600\" height=\"200\" align=\"center\" /> \n",
    "</center>   \n",
    "</figure>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab698e08-33bf-45c2-8b16-306084b6bf78",
   "metadata": {
    "tags": []
   },
   "source": [
    "## <span style=\"color:#4361EE\">Introducción</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5afaa39-c04c-4c8d-acfd-6c8de659d7ab",
   "metadata": {},
   "source": [
    "Tomado de [Wikipedia](https://en.wikipedia.org/wiki/PyTorch_Lightning)\n",
    "\n",
    "PyTorch Lightning es una biblioteca Python de código abierto que proporciona una interfaz de alto nivel para PyTorch , un marco de aprendizaje profundo popular. Es un marco liviano y de alto rendimiento que organiza el código PyTorch para desvincular la investigación de la ingeniería, lo que hace que los experimentos de aprendizaje profundo sean más fáciles de leer y reproducir. Está diseñada para crear modelos de aprendizaje profundo escalables que pueden ejecutarse fácilmente en hardware distribuido y mantener los modelos independientes del hardware.\n",
    "\n",
    "En 2019, Lightning fue adoptado por NeurIPS Reproducibility Challenge como estándar para enviar el código PyTorch a la conferencia."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e37e37-4c2f-4c66-8712-884061bb7225",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Entrenamiento de un modelo con Pythorch-lightning</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363a0b2a-2680-47b4-951a-70a2bb5f92ec",
   "metadata": {},
   "source": [
    "La siguiente imagen representa los diferentes objetos requeridos para entrenar un modelo supervisado de redes neuronales. En general cada uno de estos objetos está presente en cualquier marco de trabajo (framework) para el entrenamiento de una red neuronal. Estos componentes son:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1fc6431-db8b-4b25-b942-19fd56635b87",
   "metadata": {},
   "source": [
    "<figure>\n",
    "<img src=\"https://raw.githubusercontent.com/AprendizajeProfundo/Libro_Fundamentos_Programacion/main/Pytorch/Imagenes/trainer.png\" width=\"800\" heigh=\"600\" valign=\"left\" />   \n",
    "</figure>\n",
    "\n",
    "Fuente: Alvaro Montenegro"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31bb64d1-5973-4aa4-a85c-b8009e510668",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Datos: entrenamiento, validación, prueba</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a008fd-cb72-409f-88cb-a6bb67882520",
   "metadata": {},
   "source": [
    "Para entrenar un modelo supervisado necesitamos datos. Por lo general los datos se separan en dos o tres grupos que llamamos:\n",
    "\n",
    "* `datos de entrenamiento`. Usualmente 70% u 80% del total de datos, elegido al azar y que son los datos que verá el optimizador en el proceso de entrenamiento; \n",
    "* `datos de validación`. Usualmente 10% 0 20%. Son datos usados durante el proceso de entrenamiento para validación en línea del modelo mientras es entrenado. Usualmente se usan con la función de pérdida y con las métricas definidas en cada caso;\n",
    "* `datos de prueba`. Son datos externos al entrenamiento. Usualmente 10% del total de dato y se usan una vez ha terminado del entrenamiento para evaluar si el modelo generaliza adecuadamente, es decir si tiene el poder productivo que se espera.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0397c16f-1d17-4ca5-9f42-efcfc39ac2b1",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Modelo: la red neuronal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4711b2fb-c849-4ee5-bb0f-8ddcedff37c5",
   "metadata": {},
   "source": [
    "Es la red neuronal que se ha diseñado para resolver el problema que se tiene entre manos. Usualmente construimos una clase en la cual de defines los componentes que tendrá la red y que serás conjuntos de capas separadas de manera lógica. En Pytorch el modelo se implementa con el método `foreward`. En este método se determina exactamente cómo funciona la red neuronal. Es el método de cálculo de la red neuronal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1743b950-e042-4563-bac9-43a62ef4741a",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenador: pérdida optimizador, métricas</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e02722-77f6-4e09-b09d-a25fe9254c74",
   "metadata": {},
   "source": [
    "Es la red neuronal que se ha diseñado para resolver el problema que se tiene entre manos. Usualmente construimos una clase en la cual de defines los componentes que tendrá la red y que serás conjuntos de capas separadas de manera lógica. En Pytorch el modelo se implementa con el método `foreward`. En este método se determina exactamente cómo funciona la red neuronal. Es el método de cálculo de la red neuronal. Es el objeto que se encarga de hacer el entrenamiento de la red. El entrenador (trainer) usualmente tiene dos componentes esenciales:\n",
    "\n",
    "* `paso de optimización` en el cual se define lo que se debe hace en cada paso del proceso de optimización;\n",
    "* `ciclo de entrenamiento` que define como ocurrirá tos el entrenamiento: `número de épocas`,  `número de pasos de optimización por época`, `criterios de parada`,  lo que escribirá en el flujo de datos para seguimiento y evaluación (`writer`), y otras cosas.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15e123bb-41ee-4527-a013-75054a458530",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Instalar Pytorch-lightning</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88284dee-f27d-44d2-b1c4-8fecab39250d",
   "metadata": {},
   "source": [
    "En consola ejecute el siguiente comando. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c749ebbe-93c1-4f06-8623-29b7ee9bd00c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#conda install -c conda-forge pytorch-lightning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ca3b9ad-e253-4a2f-97bf-c91b15a230fa",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Ejemplo de una plantilla para usar PyTorch Lightning</span> "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "917ae178-4dcf-4dd4-897f-4ff332a380b8",
   "metadata": {},
   "source": [
    "Como ejemplo vamos a implementar un clasificador para los datos de MNIST, usando Lightning. Esta es una plantilla bastante general y está basada en la plantilla desarrollada por los autores de PyTorch Lightning. Puede revisar el código original en [Github](https://github.com/Lightning-AI/deep-learning-project-template/blob/master/project/lit_image_classifier.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efb1368-831a-470d-b5a9-727baf7e0252",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Importa módulos</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9adee6fd-279a-4408-acfd-1d7af590f848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "from torchvision.datasets.mnist import MNIST\n",
    "from torchvision import transforms\n",
    "\n",
    "import torchmetrics # métricas\n",
    "\n",
    "from pytorch_lightning import seed_everything # reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ef608b-d54d-4067-a813-af955f404d1d",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase Backbone: Nuestro modelo neuronal</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9bd477-d30d-4d08-8941-3f15f2fbbee0",
   "metadata": {},
   "source": [
    "Definimos nuestra red neuronal con la clase *Backbone* que deriva de  la clase `torch.nn.Module`. Al hacer esto, se gana toda la implementacion disponible en la clase Definimos nuestra red neuronal con la clase *Backbone* que deriva de  la clase *torch.nn.Module*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb0ce4e-dae8-44b4-81a7-293f64f236d5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modelo\n",
    "\n",
    "class Backbone(torch.nn.Module):\n",
    "    def __init__(self, hidden_dim=128):\n",
    "        super().__init__()\n",
    "        self.l1 = torch.nn.Linear(28 * 28, hidden_dim)\n",
    "        self.l2 = torch.nn.Linear(hidden_dim, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = torch.relu(self.l1(x))\n",
    "        x = torch.relu(self.l2(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae73bb1c-750c-4682-a181-c2b80c340285",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Clase  LitClassifier Nuestra clase Lightning</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba746771-5f8a-442b-8845-136d946c0b56",
   "metadata": {},
   "source": [
    "Esta clase heredada de `pl.LightningModule`  nos permite implementar los métodos que usará el entrenador para entrenar nuestra red. Es necesario especificar:\n",
    "\n",
    "* el método de cálculo de la red (`forward`). En realidad, podemos definir la red dentro de esta clase, pero para desacoplar la rede y hacerlo esta clase más genérica, mejor definimos el modelo por fuera. de esta clase pytorch-lightning;\n",
    "* el paso de entrenamiento, en el cual adicionalmente escribimos en el log para Tensorboard;\n",
    "* el paso de validación, que también escribe el en log para Tensorboard;\n",
    "* el paso de prueba, que también escribe el en log para Tensorboard; \n",
    "* se configura el optimizador;\n",
    "* las métricas de evaluación se definen en el constructor. Estas se van acumulando en cada paso de datos por el optimizador (trainig_step) y deben ser reinicializadas al final de cada época. De esto último se encarga PyTorch-Lightning de manera automática.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142e839-5c82-431d-9bdc-252a928ba128",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "class LitClassifier(pl.LightningModule):\n",
    "    def __init__(self, backbone, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        # modelo\n",
    "        self.backbone = backbone\n",
    "        # métricas\n",
    "        self.train_acc = torchmetrics.Accuracy()\n",
    "        self.valid_acc = torchmetrics.Accuracy()\n",
    "        self.test_acc = torchmetrics.Accuracy()\n",
    "        # rata de aprendizaje\n",
    "        self.lr = learning_rate\n",
    "\n",
    "    def forward(self, x):\n",
    "        # use forward para inferencia/predicciones\n",
    "        embedding = self.backbone(x)\n",
    "        return embedding\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de entrenamiento\n",
    "        x, y = batch\n",
    "        # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # sube la pérdida de entrenamiento al log \n",
    "        self.log('train_loss', loss, on_epoch=True)\n",
    "        # actualiza las métricas para los datos de entrenamiento\n",
    "        self.train_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de entrenamiento al log \n",
    "        self.log('train_acc', self.train_acc, on_step=True, on_epoch=False)\n",
    "        # retorna la pérdida\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de valicación\n",
    "        x, y = batch\n",
    "        # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # actualiza las métricas para los datos de validación\n",
    "        self.valid_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de validación al log \n",
    "        self.log('valid_acc', self.valid_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        # recibe batch de datos de prueba\n",
    "        x, y = batch\n",
    "         # calcula el modelo(la red) con estos datos\n",
    "        y_hat = self.backbone(x)\n",
    "        # calcula la pérdida para estos datos\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        # sube la pérdida de prueba al log\n",
    "        self.log('test_loss', loss)\n",
    "         # actualiza las métricas para los datos de validación\n",
    "        self.test_acc(y_hat, y)\n",
    "        # sube las métricas de los datos de test al log \n",
    "        self.log('test_acc', self.test_acc, on_step=True, on_epoch=True)\n",
    "\n",
    "\n",
    "        \n",
    "    def training_epoch_end(self, outs):\n",
    "        # define aqui las acciones al terminar una época en entrenamiento\n",
    "        pass\n",
    "    \n",
    "    def validation_epoch_endd(self, outs):\n",
    "        # define aqui las acciones al terminar una época en validación\n",
    "        pass\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(), lr=self.lr)\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40428aaf-6978-4dd5-9ed0-8328234ae5e9",
   "metadata": {},
   "source": [
    "### <span style=\"color:#4CC9F0\">Datos: Datasets y Dataloaders</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "313a10d6-e2e5-4a88-9a5d-63b7856d70c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Tamaño de los lotes de datos para el entrenamiento\n",
    "batch_size = 32\n",
    "# número de trabajadores para distribuir el trabajo de los dataloaders\n",
    "num_workers=4\n",
    "# Cuando mezclar los bloques de datos\n",
    "shuffle = True\n",
    "\n",
    "# creación de datasets desde Pytorch\n",
    "dataset = MNIST('', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test = MNIST('', train=False, download=True, transform=transforms.ToTensor())\n",
    "mnist_train, mnist_val = random_split(dataset, [55000, 5000])\n",
    "\n",
    "# creación de los dataloaders\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, num_workers=num_workers, shuffle=shuffle)\n",
    "val_loader = DataLoader(mnist_val, batch_size=batch_size,num_workers=num_workers)\n",
    "test_loader = DataLoader(mnist_test, batch_size=batch_size,num_workers=num_workers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd1a9d1-a2f2-4348-9271-f74831b07959",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenador</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57cf784-3f40-437b-9717-4c44ee8baaf1",
   "metadata": {
    "tags": []
   },
   "source": [
    "Instancia un entrenador que será una instancia de `Trainer`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17c61b2-3c60-4379-8549-f5ad426d856f",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Reproducibilidad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90e9dc75-33aa-49c4-bb62-57294db230cc",
   "metadata": {
    "tags": []
   },
   "source": [
    "Para garantizar la reproducibilidad total de una ejecución a otra, debemos configurar semillas para generadores pseudoaleatorios y establecer una bandera determinista en *Trainer*. Usaremos *seed_everything*.\n",
    "\n",
    "Aquí *Workers=True* en *seed_everything()*, Lightning obtiene semillas únicas en todos los procesos y trabajadores del cargador de datos para generadores de números aleatorios *torch, numpy y stdlib*. Cuando está encendido, asegura que, p. los aumentos de datos no se repiten entre los trabajadores.\n",
    "\n",
    "También deberíamos notar: determinista=Verdadero en entrenador.\n",
    "\n",
    "Sin embargo, si solo planea establecer una semilla aleatoria para python, numpy, pytorch. y no usas pytorch lightning para entrenar. seed_everything() es de hecho.\n",
    "\n",
    "Porque seed_everything() se implementa de la siguiente manera:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5fc9fb3-9ebe-4cd4-a683-24095f2450d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "os.environ[\"PL_GLOBAL_SEED\"] = str(seed)\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b17643-8039-4e37-99a4-de14b3160035",
   "metadata": {},
   "source": [
    "#### Aceleradores de hardware"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6f503a-fa14-4f5d-877c-29830445f450",
   "metadata": {},
   "source": [
    "Con PyTorch Lightning es posible actualmente utilizar los siguientes tipos de aceleradores de hardware\n",
    "\n",
    "* GPU\n",
    "* TPU\n",
    "* IPU\n",
    "* HPU\n",
    "\n",
    "\n",
    "Tenga en cuenta que Pytorch no trabaja bien con múltiples cpu's y gpu's en entrenamiento. Nuestro consejo es:\n",
    "\n",
    "* Use múltiples procesos (workers) en los dataloaders.\n",
    "* Use múltiples gpu's en el Trainer.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d53805-5e50-4da8-8052-3eddc119d621",
   "metadata": {},
   "source": [
    "#### Instanciando el entrenador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e991d548-81dc-4830-8416-bfa991877e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "#trainer = pl.Trainer(gpus=4, precisión=16, limit_train_batches=0.5)\n",
    "max_epochs = 10\n",
    "acelerator = 'cpu'\n",
    "\n",
    "# reproducibilidad\n",
    "seed_everything(42, workers=True)\n",
    "# Al escribir la línea anterior es necesario escribir. \n",
    "# Caso contrario deterministic=False, que se tiene por defecto\n",
    "deterministic=True\n",
    "# Cuántas gpus usar\n",
    "gpus = 0 # depende de sus recursos\n",
    "\n",
    "trainer = pl.Trainer(accelerator=acelerator, max_epochs= max_epochs, \n",
    "                     deterministic=deterministic, gpus=gpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4733291c-3508-43f9-b71b-90fa8279e287",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Entrenamiento</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d93a64ab-5597-4367-90f8-44a755d8ecb6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hidden_dim = 128\n",
    "\n",
    "model = LitClassifier(Backbone(hidden_dim=hidden_dim))\n",
    "trainer.fit(model, train_loader, val_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3408f8-754d-43f4-881e-bd3a1e3f7265",
   "metadata": {
    "tags": []
   },
   "source": [
    "### <span style=\"color:#4CC9F0\">Prueba</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf20a332-ed3e-471a-a7be-6185492f60fe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result = trainer.test(dataloaders=test_loader)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02a33585-cdec-424d-9a80-5ac0add3f382",
   "metadata": {},
   "source": [
    "## <span style=\"color:#4361EE\">Lanzar Tensorboard para examinar los resultados</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b294305-ae71-429d-b63c-744064ab14bf",
   "metadata": {},
   "source": [
    "Terminamos esta lección ejecutando Tensorboard, la poderosa herramienta desarrollada por Google para visualizar los resultados del entrenamiento. Tensorboard tiene muchas características interesantes. Revise las lecciones de Tonsorboard para TensorFlow y PyTorch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8234665f-0c55-4463-861f-973aa51afad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "%tensorboard --logdir lightning_logs/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
