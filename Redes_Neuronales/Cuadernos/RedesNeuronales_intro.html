
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Introducción a Redes Neuronales &#8212; Fundamentos de IA y AP</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Funciones de Activación" href="Activation_Functions.html" />
    <link rel="prev" title="Mapas Auto-organizados (SOM)" href="../../Machine_Learning/Cuadernos/som_Introduccion.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-final-ap.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Fundamentos de IA y AP</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorial.html">
                    <span style="color:#F72585">Bienvenido(a)</span>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Conociendo el libro
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Inicio/Cuadernos/Consideraciones.html">
   <span style="color:#F72585">
    Conociendo el Libro
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fundamentos de Estadística
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Conceptos_Basicos.html">
   <span style="color:#F72585">
    Probabilidad
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Variables_Aleatorias.html">
   <span style="color:#F72585">
    Variables Aleatorias
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Var_Prob_conjunta.html">
   <span style="color:#F72585">
    Probabilidad Conjunta y Entropía Cruzada
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Distribuciones_continuas.html">
   <span style="color:#F72585">
    Distribuciones de probabilidad continuas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Regresi%C3%B3n-Lineal-Pyton-Copy1.html">
   <span style="color:#F72585">
    Regresión Lineal en Python
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Teoría de la Información
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/ti_Teoria_Informacion.html">
   <span style="color:#F72585">
    Teoría de la Información
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Álgebra Lineal
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Intro_Tensores_I.html">
   <span style="color:#F72585">
    Introducción a tensores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Intro_Tensores_II.html">
   <span style="color:#F72585">
    Tensores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Tensor_Distribucion_Prob.html">
   <span style="color:#F72585">
    Tensores y distribuciones de probabilidad
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Modelación
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/mod_Modelamiento.html">
   <span style="color:#F72585">
    Ejemplos de Modelos
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/mod_Ejemplo_Modelamiento.html">
   <span style="color:#F72585">
    Ejemplos de Modelamiento
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/cal_derivadas.html">
   <span style="color:#F72585">
    Introducción a la Derivación
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Optimization_1.html">
   <span style="color:#F72585">
    Optimización univariada usando JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Optimization_2.html">
   <span style="color:#F72585">
    Optimización multivariada usando JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/am-sdg.html">
   <span style="color:#F72585">
    Optimización
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje de máquinas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_intro_aprendizaje_maquinas.html">
   <span style="color:#F72585">
    Conceptos básicos de aprendizaje de máquinas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_Regresion_logistica_JAX.html">
   <span style="color:#F72585">
    Modelo Lineal de Clasificación  con JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_Regresion_Logistica_Tensorflow.html">
   <span style="color:#F72585">
    Modelo Logístico de Clasificación  con Tensorflow 2.X
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_regresion_Keras.html">
   <span style="color:#F72585">
    Regresion Basica con tf.keras: Predecir eficiencia de la gasolina
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am-logistico-keras-cancer.html">
   <span style="color:#F72585">
    Modelo logístico de predicción en tf.keras
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje de máquinas no supervisado
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/BreveIntroduccion2R.html">
   <span style="color:#F72585">
    Breve introducción a R
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/AprendizajeNoSupervisado.html">
   <span style="color:#F72585">
    Aprendizaje no supervisado
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACP.html">
   <span style="color:#F72585">
    Análisis en componentes principales
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACS.html">
   <span style="color:#F72585">
    Análisis de correspondencias simples
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACM.html">
   <span style="color:#F72585">
    Análisis de correspondencias múltiples (ACM)
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Mapas auto-organizados (SOM)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/som_Introduccion.html">
   <span style="color:#F72585">
    Mapas Auto-organizados (SOM)
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Redes Neuronales
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <span style="color:#F72585">
    Introducción a Redes Neuronales
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Activation_Functions.html">
   <span style="color:#F72585">
    Funciones de Activación
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Hello_World_ML.html">
   <span style="color:#F72585">
    Introducción a Keras Sequential y API Funcional
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_Keras_Sequential.html">
   <span style="color:#F72585">
    Introducción a la API Sequential de Keras
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_Keras_Functional.html">
   <span style="color:#F72585">
    Introducción a la API funcional de Keras
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am-softmax-keras-iris.html">
   <span style="color:#F72585">
    Clasificación, Softmax, Iris
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am_regresion_Keras_gasolina.html">
   <span style="color:#F72585">
    Regresion Basica con tf.keras: Predecir eficiencia de la gasolina
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am-subclassing-iris.html">
   <span style="color:#F72585">
    Subclassing-Modelo de Regresión multi-logística
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NN_Animation2.html">
   <span style="color:#F72585">
    Visualización del Entrenamiento de una Red Neuronal
   </span>
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AprendizajeProfundo/Libro-Fundamentos/main?urlpath=tree/Redes_Neuronales/Cuadernos/RedesNeuronales_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/AprendizajeProfundo/Libro-Fundamentos/blob/main/Redes_Neuronales/Cuadernos/RedesNeuronales_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos/issues/new?title=Issue%20on%20page%20%2FRedes_Neuronales/Cuadernos/RedesNeuronales_intro.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos/edit/main/Redes_Neuronales/Cuadernos/RedesNeuronales_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/Redes_Neuronales/Cuadernos/RedesNeuronales_intro.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-que-es-una-red-neuronal-artificial-span">
   <span style="color:#4361EE">
    ¿Qué es una Red Neuronal Artificial?
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-somos-electricidad-span">
     <span style="color:#4CC9F0">
      Somos Electricidad
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-partes-de-una-neurona-y-sus-funciones-span">
     <span style="color:#4CC9F0">
      Partes de una Neurona y sus Funciones
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-comparacion-entre-redes-neuronales-biologicas-y-artificiales-span">
     <span style="color:#4CC9F0">
      Comparación entre Redes Neuronales Biológicas y Artificiales
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-arquitecturas-de-redes-neuronales-modernas-span">
     <span style="color:#4CC9F0">
      Arquitecturas de redes neuronales modernas
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-enfoque-matematico-de-una-rna-span">
   <span style="color:#4361EE">
    Enfoque Matemático de una RNA
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-como-funciona-una-red-neuronal-artificial-span">
     <span style="color:#4CC9F0">
      ¿Cómo funciona una Red Neuronal Artificial?
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-supuestos-basicos-span">
     <span style="color:#4CC9F0">
      Supuestos básicos
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-modelo-matematico-de-una-rna-con-una-capa-oculta-span">
     <span style="color:#4CC9F0">
      Modelo matemático de una RNA con una capa oculta
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#datos-de-entrenamiento">
       Datos de entrenamiento
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transformacion-afin-de-los-datos">
       Transformación afín de los datos.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activacion-de-neuronas-en-la-capa-oculta">
       Activación de Neuronas en la capa oculta
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#desde-la-capa-oculta-a-la-capa-de-salida">
     Desde la capa oculta a la capa de salida
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Transformación afín de los datos
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activacion-de-neuronas-en-la-capa-de-salida">
       Activación de Neuronas en la capa de salida
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-por-que-necesitamos-funciones-de-activacion-no-lineales-span">
   <span style="color:#4361EE">
    ¿Por qué necesitamos funciones de activación no lineales?
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-blue-una-rna-es-una-funcion-vectorial-span">
   <span style="color:blue">
    Una RNA es una función vectorial
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><span style="color:#F72585">Introducción a Redes Neuronales</span></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-que-es-una-red-neuronal-artificial-span">
   <span style="color:#4361EE">
    ¿Qué es una Red Neuronal Artificial?
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-somos-electricidad-span">
     <span style="color:#4CC9F0">
      Somos Electricidad
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-partes-de-una-neurona-y-sus-funciones-span">
     <span style="color:#4CC9F0">
      Partes de una Neurona y sus Funciones
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-comparacion-entre-redes-neuronales-biologicas-y-artificiales-span">
     <span style="color:#4CC9F0">
      Comparación entre Redes Neuronales Biológicas y Artificiales
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-arquitecturas-de-redes-neuronales-modernas-span">
     <span style="color:#4CC9F0">
      Arquitecturas de redes neuronales modernas
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-enfoque-matematico-de-una-rna-span">
   <span style="color:#4361EE">
    Enfoque Matemático de una RNA
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-como-funciona-una-red-neuronal-artificial-span">
     <span style="color:#4CC9F0">
      ¿Cómo funciona una Red Neuronal Artificial?
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-supuestos-basicos-span">
     <span style="color:#4CC9F0">
      Supuestos básicos
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-modelo-matematico-de-una-rna-con-una-capa-oculta-span">
     <span style="color:#4CC9F0">
      Modelo matemático de una RNA con una capa oculta
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#datos-de-entrenamiento">
       Datos de entrenamiento
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#transformacion-afin-de-los-datos">
       Transformación afín de los datos.
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activacion-de-neuronas-en-la-capa-oculta">
       Activación de Neuronas en la capa oculta
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#desde-la-capa-oculta-a-la-capa-de-salida">
     Desde la capa oculta a la capa de salida
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       Transformación afín de los datos
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#activacion-de-neuronas-en-la-capa-de-salida">
       Activación de Neuronas en la capa de salida
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-por-que-necesitamos-funciones-de-activacion-no-lineales-span">
   <span style="color:#4361EE">
    ¿Por qué necesitamos funciones de activación no lineales?
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-blue-una-rna-es-una-funcion-vectorial-span">
   <span style="color:blue">
    Una RNA es una función vectorial
   </span>
  </a>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="span-style-color-f72585-introduccion-a-redes-neuronales-span">
<h1><span style="color:#F72585">Introducción a Redes Neuronales</span><a class="headerlink" href="#span-style-color-f72585-introduccion-a-redes-neuronales-span" title="Enlazar permanentemente con este título">#</a></h1>
<p>Introducción</p>
<figure>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/mind-544404__340.webp" width="600" height="400" align="center" /> 
</figure>
<p>Fuente: <a class="reference external" href="https://pixabay.com/es/images/search/neurons/">imágenes libres en pixabay</a></p>
<section id="span-style-color-4361ee-que-es-una-red-neuronal-artificial-span">
<h2><span style="color:#4361EE">¿Qué es una Red Neuronal Artificial?</span><a class="headerlink" href="#span-style-color-4361ee-que-es-una-red-neuronal-artificial-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>Las Redes Neuronales Artificiales son modelos computacionales inspirados en el cerebro humano. Muchos de los avances recientes en ciencia y tecnología se han hecho en el campo de la Inteligencia Artificial, que van desde reconocimiento de voz hablada, reconocimiento de imágenes, y robótica, entre otros.</p>
<p>Como se dijo anteriormente, las Redes Neuronales Artificiales son simulaciones inspiradas en el ámbito biológico hechas en un ordenador para realizar tareas como</p>
<ol class="simple">
<li><p>Clustering</p></li>
<li><p>Clasificación</p></li>
<li><p>Reconocimiento de Patrones</p></li>
</ol>
<p>Aunque en general, se usan para resolver objetivos específicos guiados por su creador.</p>
<section id="span-style-color-4cc9f0-somos-electricidad-span">
<h3><span style="color:#4CC9F0">Somos Electricidad</span><a class="headerlink" href="#span-style-color-4cc9f0-somos-electricidad-span" title="Enlazar permanentemente con este título">#</a></h3>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/brain-5885161_960_720.webp" width="500" height="400" align="center" /> 
</center>   
</figure>
<p>Fuente: <a class="reference external" href="https://pixabay.com/es/images/search/neurons/">pixabay: imágenes libres</a></p>
</section>
<section id="span-style-color-4cc9f0-partes-de-una-neurona-y-sus-funciones-span">
<h3><span style="color:#4CC9F0">Partes de una Neurona y sus Funciones</span><a class="headerlink" href="#span-style-color-4cc9f0-partes-de-una-neurona-y-sus-funciones-span" title="Enlazar permanentemente con este título">#</a></h3>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/Structure-Of-Neurons-In-Brain.jpeg" width="600" height="300" align="center" /> 
</center>   
</figure>
<p>Fuente: Alvaro Montenegro, basado en una imagen de <a class="reference external" href="https://pixabay.com/es/images/search/neurons/">pixabay</a></p>
<p>Las células nerviosas típicas del cerebro humano se compone de cuatro partes:</p>
<ol class="simple">
<li><p><strong>Función de la Dendrita</strong>. Recibe las señales de otras neuronas.</p></li>
<li><p><strong>Soma (cuerpo celular)</strong>. Suma todas las señales entrantes para generar una señal total de entrada(input).</p></li>
<li><p><strong>Estructura del Axón</strong>. Cuando la suma sobrepasa un cierto umbral numérico, la neurona se activa, dispara y la señal viaja a través del axón hacia otras neuronas.</p></li>
<li><p><strong>Trabajo de la Sinapsis</strong>. Es el punto donde se realiza la interconexión de una neurona con otras neuronas. La cantidad de la señal transmitida depende en la fuerza (peso sináptico) de las conexiones. Las conexiones pueden ser inhibidoras (disminuyendo la fuerza) o de excitación (aumentando la fuerza) en principio.</p></li>
</ol>
<p>Así pues, una <strong>Red Neuronal</strong> es, en general una <strong>red altamente interconectada</strong> de billones de neuronas con trillones de interconexiones entre ellas.</p>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/neurons-1773922__340.webp" width="600" height="300" align="center" /> 
</center>   
</figure>
<p>Fuente: <a class="reference external" href="https://pixabay.com/es/images/search/neurons/">Pixabay: imágenes libres</a></p>
</section>
<section id="span-style-color-4cc9f0-comparacion-entre-redes-neuronales-biologicas-y-artificiales-span">
<h3><span style="color:#4CC9F0">Comparación entre Redes Neuronales Biológicas y Artificiales</span><a class="headerlink" href="#span-style-color-4cc9f0-comparacion-entre-redes-neuronales-biologicas-y-artificiales-span" title="Enlazar permanentemente con este título">#</a></h3>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/electronics-3007664_960_720.jpg" width="600" height="300" align="center" /> 
</center>   
</figure>
<p>Fuente: <a class="reference external" href="https://pixabay.com/es/photos/electr%c3%b3nica-circuito-integrado-3007664/">Pixabay: imágenes libres</a></p>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/neurona_artificial.png" width="600" height="300" align="center" /> 
</center>   
</figure>
<p>Fuente: Alvaro Montenegro</p>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/neural_network.png" width="600" height="300" align="center" /> 
</center>   
</figure>
<p>Fuente: <a class="reference external" href="https://www.clipartmax.com/download/m2i8d3G6b1b1K9i8_%5B2%5D-image-on-quoracdn-machine-learning-neural-networks/">ClipArtMax</a></p>
<p>Las <strong>dendritas</strong> in las Redes Neuronales Biológicas son un análogo a las entradas conteniendo un peso especifico basada en la interconexión «sináptica» presente en la Red Neuronal Artificial.</p>
<p>El <strong>cuerpo celular</strong> es comparable a la unidad artificial llamada «neurona» en una Red Neuronal Artificial, que también comprende la suma de señales y umbral de activación.</p>
<p>La salida de los <strong>Axones</strong> (presentes en la sinapsis) son el análogo de los datos de salida en la Red Neuronal Artificial.</p>
<p>Por lo tanto, <strong>RNA</strong> son modeladas usando el trabajo básico de las neuronas biológicas.</p>
</section>
<section id="span-style-color-4cc9f0-arquitecturas-de-redes-neuronales-modernas-span">
<h3><span style="color:#4CC9F0">Arquitecturas de redes neuronales modernas</span><a class="headerlink" href="#span-style-color-4cc9f0-arquitecturas-de-redes-neuronales-modernas-span" title="Enlazar permanentemente con este título">#</a></h3>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/RN_modernas.png" width="800" height="500" align="center" /> 
</center>   
</figure>
<p>Fuente: Alvaro Montenegro</p>
<ol class="simple">
<li><p><strong>Red neuronal de perceptrón multicapa</strong>. Estas redes utilizan <strong>más de una capa oculta</strong> de neuronas, a diferencia del perceptrón de una sola capa. También se conocen como Redes neuronales de alimentación profunda.</p></li>
<li><p><strong>RNA convolucional</strong>. Esta redes se basan en el concepto matemáticos de convolución. Esencialmente se basan en filtros que se aplican por ejemplo a las imágenes. Los filtros son estimados para cada red.</p></li>
<li><p><strong>Transformer</strong>. Estas redes son especiales para el tratamiento de procesamiento de lenguaje natural. Recientemente han sido aplicadas a series de tiempo e imágenes. Se basan en el concepto de auto-atención.</p></li>
<li><p><strong>Red neuronal recurrente</strong>. Tipo de red neuronal en la que las neuronas de cada capa oculta tienen <strong>auto-conexiones</strong>. Las redes neuronales recurrentes <strong>poseen memoria</strong>. En cualquier caso, la neurona de capa oculta recibe la activación de la siguiente capa, así como su valor de activación anterior. Muy usadas principalmente emn series de tiempo. Los modelos más conocidos con LSTM y GRU.</p></li>
<li><p><strong>Red autocodificadora</strong> o auto-encoder. Es esencialmente un perceptrón multicapa de múltiples usos como parte de otras arquitecturas. Por sí mismas son útiles para hacer reducción de dimensión de los datos.</p></li>
</ol>
</section>
</section>
<section id="span-style-color-4361ee-enfoque-matematico-de-una-rna-span">
<h2><span style="color:#4361EE">Enfoque Matemático de una RNA</span><a class="headerlink" href="#span-style-color-4361ee-enfoque-matematico-de-una-rna-span" title="Enlazar permanentemente con este título">#</a></h2>
<section id="span-style-color-4cc9f0-como-funciona-una-red-neuronal-artificial-span">
<h3><span style="color:#4CC9F0">¿Cómo funciona una Red Neuronal Artificial?</span><a class="headerlink" href="#span-style-color-4cc9f0-como-funciona-una-red-neuronal-artificial-span" title="Enlazar permanentemente con este título">#</a></h3>
<figure>
<center>
<img src="https://raw.githubusercontent.com/AprendizajeProfundo/Libro-Fundamentos/main/Redes_Neuronales/Imagenes/ANN_Capa_Oculta.png" width="800" height="600" align="center" /> 
</center>   
</figure>
<p>Fuente: Alvaro Montenegro</p>
<p>La red neuronal artificial recibe información del mundo externo en forma de patrón en forma de vector, digamos <span class="math notranslate nohighlight">\(x=(x_1,\ldots,x_n)^t\)</span>. En este caso, la capa de entrada posee <span class="math notranslate nohighlight">\(n\)</span> neuronas artificiales.</p>
<p>Cada componente <span class="math notranslate nohighlight">\(x_i\)</span> de la entrada se multiplica por el peso correspondiente <span class="math notranslate nohighlight">\(w_{i}\)</span>. Los pesos son la información utilizada por la red neuronal para resolver un problema específico. Estos pesos deben aprenderse (ajustarse, estimarse) en el <strong>paso de entrenamiento</strong>. Los <strong>pesos representan el conocimiento</strong> que tienen los ANN sobre el problema en cuestión.</p>
<p>Usando la metáfora biológica, los pesos representan la fuerza de la interconexión entre las neuronas dentro de la red neuronal.</p>
<p>Las entradas y los pesos se combinan y se resumen dentro de la unidad de computación (neurona artificial), y se agrega un <strong>«sesgo»</strong> (intercepto), como muestra la figura arriba.</p>
<p>La suma es un número real: <span class="math notranslate nohighlight">\(z = \sum_i x_iw_i + b\)</span>, <span class="math notranslate nohighlight">\(z \in\mathcal{R}\)</span>. Esta suma se transforma a través de una función de activación, digamos <span class="math notranslate nohighlight">\(g(\cdot)\)</span>, para obtener la salida neta <span class="math notranslate nohighlight">\(x^* = g(z)\)</span>. La función de activación determina el comportamiento de la neurona. Para más detalles, consulte la siguiente sección.</p>
</section>
<section id="span-style-color-4cc9f0-supuestos-basicos-span">
<h3><span style="color:#4CC9F0">Supuestos básicos</span><a class="headerlink" href="#span-style-color-4cc9f0-supuestos-basicos-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>La primera capa oculta de un RNA podría ser una reducción de dimensión. Sin embargo, en general, es más práctico reducir los datos previamente. Entonces, a partir de este punto, suponemos que los datos de entrenamiento son datos reducidos (si es que tal reducción es necesaria).</p>
<p>En esta sección consideramos sólo una capa oculta.
<strong>Asumiremos</strong> que:</p>
<ol class="simple">
<li><p>La capa de entrada tiene <span class="math notranslate nohighlight">\(n\)</span> neuronas. Entonces los valores de entrada son <span class="math notranslate nohighlight">\(n\)</span>-vectores.</p></li>
<li><p>La capa oculta tiene <span class="math notranslate nohighlight">\(q\)</span> neuronas. Esto implica que existen conexiones <span class="math notranslate nohighlight">\(q\)</span> desde cada neurona de entrada a la capa oculta. En total hay conexiones <span class="math notranslate nohighlight">\(n \times q\)</span> entre la capa de entrada y la capa oculta. Cada conexión tiene un peso <span class="math notranslate nohighlight">\(w^{1}_{ij}\)</span>, que representa la fuerza de la conexión entre la neurona <span class="math notranslate nohighlight">\(i\)</span> en la capa de entrada y la neurona <span class="math notranslate nohighlight">\(j\)</span> en la capa oculta.</p></li>
<li><p>La capa de salida tiene neuronas <span class="math notranslate nohighlight">\(L\)</span>. Esto implica que existen conexiones <span class="math notranslate nohighlight">\(L\)</span> de cada neurona oculta a la capa de salida. En total hay conexiones <span class="math notranslate nohighlight">\(q \times L\)</span> entre la capa oculta y la capa de salida. Cada conexión tiene un peso <span class="math notranslate nohighlight">\(w^{2}_{jk}\)</span>, que representa la fuerza de la conexión entre la neurona <span class="math notranslate nohighlight">\(j\)</span> en la capa oculta y la neurona <span class="math notranslate nohighlight">\(k\)</span> en la capa de salida.</p></li>
</ol>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> <strong>Notación Vectorial</strong>. <em>Por facilidad, denotaremos los vectores en un formato de fila, como es habitual en matemáticas. En estadística es común la notación de columna</em>.</p>
</section>
<section id="span-style-color-4cc9f0-modelo-matematico-de-una-rna-con-una-capa-oculta-span">
<h3><span style="color:#4CC9F0">Modelo matemático de una RNA con una capa oculta</span><a class="headerlink" href="#span-style-color-4cc9f0-modelo-matematico-de-una-rna-con-una-capa-oculta-span" title="Enlazar permanentemente con este título">#</a></h3>
<section id="datos-de-entrenamiento">
<h4>Datos de entrenamiento<a class="headerlink" href="#datos-de-entrenamiento" title="Enlazar permanentemente con este título">#</a></h4>
<p>Sea <span class="math notranslate nohighlight">\(X_{N\times n}\)</span> la matriz de los datos de entrenamiento de entrada <span class="math notranslate nohighlight">\(N\)</span>.</p>
</section>
<section id="transformacion-afin-de-los-datos">
<h4>Transformación afín de los datos.<a class="headerlink" href="#transformacion-afin-de-los-datos" title="Enlazar permanentemente con este título">#</a></h4>
<p>Sea <span class="math notranslate nohighlight">\(W^{1}\)</span> una matriz <span class="math notranslate nohighlight">\(n\times q\)</span>  cuyas filas son los vectores de peso <span class="math notranslate nohighlight">\(w^{1}_{ij}\)</span>,
que conceptualmente conectan la capa de entrada con la capa oculta. Sea <span class="math notranslate nohighlight">\(b^{1}\)</span> el <span class="math notranslate nohighlight">\(q\)</span>-vector de los respectivos bias. Supongamos que <span class="math notranslate nohighlight">\(b=(b^1_1,\ldots, b^1_j,\ldots,b^1_q)\)</span>. Entonces , <span class="math notranslate nohighlight">\(b^1_j\)</span> es el bias en la neurona <span class="math notranslate nohighlight">\(j\)</span> de la capa oculta.</p>
<p>Dado un vector de entrada <span class="math notranslate nohighlight">\(x\)</span>, que es fila de matriz <span class="math notranslate nohighlight">\(X\)</span>, la entrada completa de la capa oculta se obtiene mediante</p>
<div class="math notranslate nohighlight">
\[
z^{1} = xW^{1} + b^{1} \quad (1)
\]</div>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> Note que hemos asumido que hay <span class="math notranslate nohighlight">\(n\)</span> neuronas en la capa de entrada. Si <span class="math notranslate nohighlight">\(q&lt;n\)</span>, <span class="math notranslate nohighlight">\(W^{1}\)</span> realiza una proyección sobre un subespacio de dimensión reducida. Si <span class="math notranslate nohighlight">\(q&gt;n\)</span>, <span class="math notranslate nohighlight">\(W^{1}\)</span> realiza un «sumergimiento» (embedding) sobre un espacio de dimensión mayor.</p>
<p>La ecuación (1) es una <strong>transformación afín</strong>, que puede ser expresada en coordenadas homogéneas de la siguiente manera:</p>
<p><span class="math notranslate nohighlight">\(\tilde{x} = (x,1)\)</span>, <span class="math notranslate nohighlight">\(\tilde{z}^1 = (z^1,1)\)</span>. Let <span class="math notranslate nohighlight">\(\tilde{W}\)</span> defined as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\tilde{W}^1 = \begin{pmatrix} W^1 &amp; 0\\ b^1 &amp; 1\end{pmatrix}
\end{split}\]</div>
<p>por lo que obtenemos,</p>
<div class="math notranslate nohighlight">
\[
\tilde{z}^1 = \tilde{x}\tilde{W}^1.
\]</div>
<p>Esta ecuación significa que una transformación afín se puede expresar como una transformación lineal en coordenadas homogéneas. Para obtener más información, consulte la próxima lección, sobre transformaciones afines.</p>
</section>
<section id="activacion-de-neuronas-en-la-capa-oculta">
<h4>Activación de Neuronas en la capa oculta<a class="headerlink" href="#activacion-de-neuronas-en-la-capa-oculta" title="Enlazar permanentemente con este título">#</a></h4>
<p>Sea <span class="math notranslate nohighlight">\(f^1\)</span> la función de activación en la capa oculta. Entonces, <span class="math notranslate nohighlight">\(f^1\)</span> se aplica a cada elemento de <span class="math notranslate nohighlight">\(z^1\)</span>. Sea <span class="math notranslate nohighlight">\(x^1 = (x_1^1,\ldots,x_j^1,\ldots, x_q^1)\)</span>. El efecto de la función de activación se escribe como</p>
<div class="math notranslate nohighlight">
\[
x^1 = f^1(z^1),
\]</div>
<p>donde <span class="math notranslate nohighlight">\(x^1_j = f^1(z^1_j)\)</span>, para <span class="math notranslate nohighlight">\(j=1,\ldots,q\)</span>.</p>
</section>
</section>
<section id="desde-la-capa-oculta-a-la-capa-de-salida">
<h3>Desde la capa oculta a la capa de salida<a class="headerlink" href="#desde-la-capa-oculta-a-la-capa-de-salida" title="Enlazar permanentemente con este título">#</a></h3>
<section id="id1">
<h4>Transformación afín de los datos<a class="headerlink" href="#id1" title="Enlazar permanentemente con este título">#</a></h4>
<p>Supongamos que <span class="math notranslate nohighlight">\(W^{2}\)</span> es una matriz <span class="math notranslate nohighlight">\(q\times L\)</span>,  cuyas filas son los vectores de pesos <span class="math notranslate nohighlight">\(w^{2}_{jk}\)</span>,  que conceptualmente conecta la capa oculta con la capa de salida. Sea <span class="math notranslate nohighlight">\(b^{2}\)</span> el <span class="math notranslate nohighlight">\(L\)</span>-vector de los correspondientes biases (interceptos).</p>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> En la aplicación de una Red Neuronal Profunda a un problema de clasificación, <span class="math notranslate nohighlight">\(L\)</span> corresponde al número de clases.</p>
<p>Dado <span class="math notranslate nohighlight">\(x^1\)</span> el vector de salida de la capa oculta, la entrada completa a la capa de salida se obtiene como</p>
<div class="math notranslate nohighlight">
\[
z^{1} = x^1W^{2} + b^{2}. \quad (2)
\]</div>
<p>En coordenadas homogéneas, tenemos que</p>
<div class="math notranslate nohighlight">
\[
\tilde{z}^2 = \tilde{x}^1\tilde{W}^2.
\]</div>
</section>
<section id="activacion-de-neuronas-en-la-capa-de-salida">
<h4>Activación de Neuronas en la capa de salida<a class="headerlink" href="#activacion-de-neuronas-en-la-capa-de-salida" title="Enlazar permanentemente con este título">#</a></h4>
<p>Sea <span class="math notranslate nohighlight">\(f^2\)</span> la función de activación en la capa de salida. Entonces, <span class="math notranslate nohighlight">\(f^2\)</span> se aplica a cada elemento de <span class="math notranslate nohighlight">\(z^2\)</span>. Sea <span class="math notranslate nohighlight">\(y = (y_1,\ldots,y_k,\ldots, y_L)\)</span>. El efecto de la función de activación se escribe como</p>
<div class="math notranslate nohighlight">
\[
y = f^2(z^2),
\]</div>
<p>donde <span class="math notranslate nohighlight">\(y_k = f^2(z^2_k)\)</span>, for <span class="math notranslate nohighlight">\(k=1,\ldots,L\)</span>.</p>
</section>
</section>
</section>
<section id="span-style-color-4361ee-por-que-necesitamos-funciones-de-activacion-no-lineales-span">
<h2><span style="color:#4361EE">¿Por qué necesitamos funciones de activación no lineales?</span><a class="headerlink" href="#span-style-color-4361ee-por-que-necesitamos-funciones-de-activacion-no-lineales-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>Una red neuronal sin funciones de activación lineal es esencialmente un modelo de regresión lineal. La función de activación realiza una transformación no lineal de la entrada, lo que la hace capaz de aprender y realizar tareas más complejas.</p>
<p>Para ver este hecho, suponga que <span class="math notranslate nohighlight">\(\tilde{G}^1\)</span> y <span class="math notranslate nohighlight">\(\tilde{G}^2\)</span> representan las matrices asociadas a las funciones de activación lineal en coordenadas homogéneas. Por lo tanto, tenemos que</p>
<div class="math notranslate nohighlight">
\[
\tilde{y} =\tilde{x}\tilde{W}^1\tilde{G}^1\tilde{W}^2\tilde{G}^2 = x\tilde{W}
\]</div>
<p>donde
$<span class="math notranslate nohighlight">\(
\tilde{W}=\tilde{W}^1\tilde{G}^1\tilde{W}^2\tilde{G}^2
\)</span>$ .</p>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> Así, en este caso la RNP se reduce a un modelo lineal simple, que no es muy útil en la práctica.</p>
</section>
<section id="span-style-color-blue-una-rna-es-una-funcion-vectorial-span">
<h2><span style="color:blue">Una RNA es una función vectorial</span><a class="headerlink" href="#span-style-color-blue-una-rna-es-una-funcion-vectorial-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>Una RNA con una capa oculta es una función <span class="math notranslate nohighlight">\(f:\mathcal{R}^n \to \mathcal{R}^L\)</span>, definida como</p>
<div class="math notranslate nohighlight">
\[
y = f(x)  = f^2(f^1( x W^1 + b^1 ) W^2 + b^2).
\]</div>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> Como puede verse, si la RNA tiene más de una capa oculta, la función <span class="math notranslate nohighlight">\(f\)</span> puede ser extendida directamente de forma recursiva.</p>
</section>
<section id="span-style-color-4361ee-referencias-span">
<h2><span style="color:#4361EE">Referencias</span><a class="headerlink" href="#span-style-color-4361ee-referencias-span" title="Enlazar permanentemente con este título">#</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://github.com/AprendizajeProfundo/Diplomado">Alvaro Montenegro y Daniel Montenegro, Inteligencia Artificial y Aprendizaje Profundo, 2021</a></p></li>
<li><p><a class="reference external" href="https://es.unesco.org/themes/tic-educacion/inteligencia-artificial">Unesco: educación e inteligencia artificial</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "AprendizajeProfundo/Libro-Fundamentos",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Redes_Neuronales\Cuadernos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="../../Machine_Learning/Cuadernos/som_Introduccion.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title"><span style="color:#F72585">Mapas Auto-organizados (SOM)</span></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Activation_Functions.html" title="siguiente página">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title"><span style="color:#F72585">Funciones de Activación</span></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Álvaro Mauricio Montenegro Díaz, Daniel Mauricio Montenegro Reyes<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>