
<!DOCTYPE html>

<html lang="es">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Funciones de Activación &#8212; Fundamentos de IA y AP</title>
    
  <!-- Loaded before other Sphinx assets -->
  <link href="../../_static/styles/theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">
<link href="../../_static/styles/pydata-sphinx-theme.css?digest=1999514e3f237ded88cf" rel="stylesheet">

    
  <link rel="stylesheet"
    href="../../_static/vendor/fontawesome/5.13.0/css/all.min.css">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-solid-900.woff2">
  <link rel="preload" as="font" type="font/woff2" crossorigin
    href="../../_static/vendor/fontawesome/5.13.0/webfonts/fa-brands-400.woff2">

    <link rel="stylesheet" type="text/css" href="../../_static/pygments.css" />
    <link rel="stylesheet" href="../../_static/styles/sphinx-book-theme.css?digest=5115cc725059bd94278eecd172e13a965bf8f5a9" type="text/css" />
    <link rel="stylesheet" type="text/css" href="../../_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/mystnb.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/tabs.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="../../_static/design-style.b7bb847fb20b106c3d81b95245e65545.min.css" />
    
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf">

    <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
    <script src="../../_static/jquery.js"></script>
    <script src="../../_static/underscore.js"></script>
    <script src="../../_static/doctools.js"></script>
    <script src="../../_static/clipboard.min.js"></script>
    <script src="../../_static/copybutton.js"></script>
    <script src="../../_static/scripts/sphinx-book-theme.js?digest=9c920249402e914e316237a7dbc6769907cce411"></script>
    <script src="../../_static/tabs.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="../../_static/togglebutton.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.4/require.min.js"></script>
    <script src="../../_static/translations.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown, .tag_hide_input div.cell_input, .tag_hide-input div.cell_input, .tag_hide_output div.cell_output, .tag_hide-output div.cell_output, .tag_hide_cell.cell, .tag_hide-cell.cell';</script>
    <script src="../../_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="../../_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <link rel="index" title="Índice" href="../../genindex.html" />
    <link rel="search" title="Búsqueda" href="../../search.html" />
    <link rel="next" title="Introducción a Keras Sequential y API Funcional" href="Hello_World_ML.html" />
    <link rel="prev" title="Introducción a Redes Neuronales" href="RedesNeuronales_intro.html" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="docsearch:language" content="es">
    

    <!-- Google Analytics -->
    
  </head>
  <body data-spy="scroll" data-target="#bd-toc-nav" data-offset="60">
<!-- Checkboxes to toggle the left sidebar -->
<input type="checkbox" class="sidebar-toggle" name="__navigation" id="__navigation" aria-label="Toggle navigation sidebar">
<label class="overlay overlay-navbar" for="__navigation">
    <div class="visually-hidden">Toggle navigation sidebar</div>
</label>
<!-- Checkboxes to toggle the in-page toc -->
<input type="checkbox" class="sidebar-toggle" name="__page-toc" id="__page-toc" aria-label="Toggle in-page Table of Contents">
<label class="overlay overlay-pagetoc" for="__page-toc">
    <div class="visually-hidden">Toggle in-page Table of Contents</div>
</label>
<!-- Headers at the top -->
<div class="announcement header-item noprint"></div>
<div class="header header-item noprint"></div>

    
    <div class="container-fluid" id="banner"></div>

    

    <div class="container-xl">
      <div class="row">
          
<!-- Sidebar -->
<div class="bd-sidebar noprint" id="site-navigation">
    <div class="bd-sidebar__content">
        <div class="bd-sidebar__top"><div class="navbar-brand-box">
    <a class="navbar-brand text-wrap" href="../../index.html">
      
        <!-- `logo` is deprecated in Sphinx 4.0, so remove this when we stop supporting 3 -->
        
      
      
      <img src="../../_static/logo-final-ap.png" class="logo" alt="logo">
      
      
      <h1 class="site-logo" id="site-title">Fundamentos de IA y AP</h1>
      
    </a>
</div><form class="bd-search d-flex align-items-center" action="../../search.html" method="get">
  <i class="icon fas fa-search"></i>
  <input type="search" class="form-control" name="q" id="search-input" placeholder="Search this book..." aria-label="Search this book..." autocomplete="off" >
</form><nav class="bd-links" id="bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item active">
        
        <ul class="nav bd-sidenav bd-sidenav__home-link">
            <li class="toctree-l1">
                <a class="reference internal" href="../../tutorial.html">
                    <span style="color:#F72585">Bienvenido(a)</span>
                </a>
            </li>
        </ul>
        <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Conociendo el libro
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Inicio/Cuadernos/Consideraciones.html">
   <span style="color:#F72585">
    Conociendo el Libro
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Fundamentos de Estadística
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Conceptos_Basicos.html">
   <span style="color:#F72585">
    Probabilidad
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Variables_Aleatorias.html">
   <span style="color:#F72585">
    Variables Aleatorias
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Var_Prob_conjunta.html">
   <span style="color:#F72585">
    Probabilidad Conjunta y Entropía Cruzada
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Prob_Distribuciones_continuas.html">
   <span style="color:#F72585">
    Distribuciones de probabilidad continuas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/Regresi%C3%B3n-Lineal-Pyton-Copy1.html">
   <span style="color:#F72585">
    Regresión Lineal en Python
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Teoría de la Información
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Estadistica/Cuadernos/ti_Teoria_Informacion.html">
   <span style="color:#F72585">
    Teoría de la Información
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Álgebra Lineal
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Intro_Tensores_I.html">
   <span style="color:#F72585">
    Introducción a tensores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Intro_Tensores_II.html">
   <span style="color:#F72585">
    Tensores
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Tensor_Distribucion_Prob.html">
   <span style="color:#F72585">
    Tensores y distribuciones de probabilidad
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Modelación
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/mod_Modelamiento.html">
   <span style="color:#F72585">
    Ejemplos de Modelos
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/mod_Ejemplo_Modelamiento.html">
   <span style="color:#F72585">
    Ejemplos de Modelamiento
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/cal_derivadas.html">
   <span style="color:#F72585">
    Introducción a la Derivación
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Optimization_1.html">
   <span style="color:#F72585">
    Optimización univariada usando JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/Optimization_2.html">
   <span style="color:#F72585">
    Optimización multivariada usando JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Fundamentacion_Matematica/Cuadernos/am-sdg.html">
   <span style="color:#F72585">
    Optimización
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje de máquinas
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_intro_aprendizaje_maquinas.html">
   <span style="color:#F72585">
    Conceptos básicos de aprendizaje de máquinas
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_Regresion_logistica_JAX.html">
   <span style="color:#F72585">
    Modelo Lineal de Clasificación  con JAX
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_Regresion_Logistica_Tensorflow.html">
   <span style="color:#F72585">
    Modelo Logístico de Clasificación  con Tensorflow 2.X
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am_regresion_Keras.html">
   <span style="color:#F72585">
    Regresion Basica con tf.keras: Predecir eficiencia de la gasolina
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/am-logistico-keras-cancer.html">
   <span style="color:#F72585">
    Modelo logístico de predicción en tf.keras
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Aprendizaje de máquinas no supervisado
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/BreveIntroduccion2R.html">
   <span style="color:#F72585">
    Breve introducción a R
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/AprendizajeNoSupervisado.html">
   <span style="color:#F72585">
    Aprendizaje no supervisado
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACP.html">
   <span style="color:#F72585">
    Análisis en componentes principales
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACS.html">
   <span style="color:#F72585">
    Análisis de correspondencias simples
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/ACM.html">
   <span style="color:#F72585">
    Análisis de correspondencias múltiples (ACM)
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Mapas auto-organizados (SOM)
 </span>
</p>
<ul class="nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="../../Machine_Learning/Cuadernos/som_Introduccion.html">
   <span style="color:#F72585">
    Mapas Auto-organizados (SOM)
   </span>
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Redes Neuronales
 </span>
</p>
<ul class="current nav bd-sidenav">
 <li class="toctree-l1">
  <a class="reference internal" href="RedesNeuronales_intro.html">
   <span style="color:#F72585">
    Introducción a Redes Neuronales
   </span>
  </a>
 </li>
 <li class="toctree-l1 current active">
  <a class="current reference internal" href="#">
   <span style="color:#F72585">
    Funciones de Activación
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Hello_World_ML.html">
   <span style="color:#F72585">
    Introducción a Keras Sequential y API Funcional
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_Keras_Sequential.html">
   <span style="color:#F72585">
    Introducción a la API Sequential de Keras
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="Intro_Keras_Functional.html">
   <span style="color:#F72585">
    Introducción a la API funcional de Keras
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am-softmax-keras-iris.html">
   <span style="color:#F72585">
    Clasificación, Softmax, Iris
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am_regresion_Keras_gasolina.html">
   <span style="color:#F72585">
    Regresion Basica con tf.keras: Predecir eficiencia de la gasolina
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="am-subclassing-iris.html">
   <span style="color:#F72585">
    Subclassing-Modelo de Regresión multi-logística
   </span>
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="NN_Animation2.html">
   <span style="color:#F72585">
    Visualización del Entrenamiento de una Red Neuronal
   </span>
  </a>
 </li>
</ul>

    </div>
</nav></div>
        <div class="bd-sidebar__bottom">
             <!-- To handle the deprecated key -->
            
            <div class="navbar_extra_footer">
            Powered by <a href="https://jupyterbook.org">Jupyter Book</a>
            </div>
            
        </div>
    </div>
    <div id="rtd-footer-container"></div>
</div>


          


          
<!-- A tiny helper pixel to detect if we've scrolled -->
<div class="sbt-scroll-pixel-helper"></div>
<!-- Main content -->
<div class="col py-0 content-container">
    
    <div class="header-article row sticky-top noprint">
        



<div class="col py-1 d-flex header-article-main">
    <div class="header-article__left">
        
        <label for="__navigation"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="right"
title="Toggle navigation"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-bars"></i>
  </span>

</label>

        
    </div>
    <div class="header-article__right">
<div class="menu-dropdown menu-dropdown-launch-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Launch interactive content">
      <i class="fas fa-rocket"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://mybinder.org/v2/gh/AprendizajeProfundo/Libro-Fundamentos/main?urlpath=tree/Redes_Neuronales/Cuadernos/Activation_Functions.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Binder"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_binder.svg">
  </span>
<span class="headerbtn__text-container">Binder</span>
</a>

      </li>
      
      <li>
        <a href="https://colab.research.google.com/github/AprendizajeProfundo/Libro-Fundamentos/blob/main/Redes_Neuronales/Cuadernos/Activation_Functions.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Launch on Colab"
>
  

<span class="headerbtn__icon-container">
  
    <img src="../../_static/images/logo_colab.png">
  </span>
<span class="headerbtn__text-container">Colab</span>
</a>

      </li>
      
      <li>
        
<button onclick="initThebeSBT()"
  class="headerbtn headerbtn-launch-thebe"
  data-toggle="tooltip"
data-placement="left"
title="Launch Thebe"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="headerbtn__text-container">Live Code</span>
</button>

      </li>
      
    </ul>
  </div>
</div>

<button onclick="toggleFullScreen()"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="bottom"
title="Fullscreen mode"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>

<div class="menu-dropdown menu-dropdown-repository-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Source repositories">
      <i class="fab fa-github"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Source repository"
>
  

<span class="headerbtn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="headerbtn__text-container">repository</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos/issues/new?title=Issue%20on%20page%20%2FRedes_Neuronales/Cuadernos/Activation_Functions.html&body=Your%20issue%20content%20here."
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Open an issue"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="headerbtn__text-container">open issue</span>
</a>

      </li>
      
      <li>
        <a href="https://github.com/AprendizajeProfundo/Libro-Fundamentos/edit/main/Redes_Neuronales/Cuadernos/Activation_Functions.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Edit this page"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="headerbtn__text-container">suggest edit</span>
</a>

      </li>
      
    </ul>
  </div>
</div>

<div class="menu-dropdown menu-dropdown-download-buttons">
  <button class="headerbtn menu-dropdown__trigger"
      aria-label="Download this page">
      <i class="fas fa-download"></i>
  </button>
  <div class="menu-dropdown__content">
    <ul>
      <li>
        <a href="../../_sources/Redes_Neuronales/Cuadernos/Activation_Functions.ipynb"
   class="headerbtn"
   data-toggle="tooltip"
data-placement="left"
title="Download source file"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="headerbtn__text-container">.ipynb</span>
</a>

      </li>
      
      <li>
        
<button onclick="printPdf(this)"
  class="headerbtn"
  data-toggle="tooltip"
data-placement="left"
title="Print to PDF"
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="headerbtn__text-container">.pdf</span>
</button>

      </li>
      
    </ul>
  </div>
</div>
<label for="__page-toc"
  class="headerbtn headerbtn-page-toc"
  
>
  

<span class="headerbtn__icon-container">
  <i class="fas fa-list"></i>
  </span>

</label>

    </div>
</div>

<!-- Table of contents -->
<div class="col-md-3 bd-toc show noprint">
    <div class="tocsection onthispage pt-5 pb-3">
        <i class="fas fa-list"></i> Contents
    </div>
    <nav id="bd-toc-nav" aria-label="Page">
        <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-introduccion-span">
   <span style="color:#4361EE">
    Introducción
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-por-que-necesitamos-funciones-de-activacion-span">
     <span style="color:#4CC9F0">
      ¿Por qué necesitamos funciones de activación?
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-funciones-de-activacion-clasicas-span">
   <span style="color:#4361EE">
    Funciones de activación clásicas
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-step-span">
     <span style="color:#4CC9F0">
      Función Step
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-activacion-lineal-span">
     <span style="color:#4CC9F0">
      Activación lineal
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funciones-de-activacion-tipo-sigmoide-span">
     <span style="color:#4CC9F0">
      Funciones de activación tipo sigmoide
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-logistica-sigmoid-span">
       <span style="color:#4CC9F0">
        Función logística (sigmoid)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-ejercicio-span">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-tangente-hiperbolica-span">
       <span style="color:#4CC9F0">
        Función de activacion Tangente hiperbólica
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-unidad-de-rectificacion-lineal-relu-span">
       <span style="color:#4CC9F0">
        Función de activación Unidad de rectificación lineal (ReLu)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-softmax-span">
       <span style="color:#4CC9F0">
        Función de activación Softmax
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-seleccionando-una-funcion-de-activacion-span">
     <span style="color:#4CC9F0">
      Seleccionando una función de activación
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-estado-del-arte-variaciones-de-la-funcion-de-activacion-de-relu-span">
   <span style="color:#4361EE">
    Estado del arte. Variaciones de la función de activación de ReLu
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-limitaciones-de-las-funciones-de-activacion-sigmoide-y-tanh-span">
     <span style="color:#4CC9F0">
      Limitaciones de las funciones de activación sigmoide y Tanh
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-evitando-que-los-gradientes-desaparezcan-mediante-el-uso-de-la-funcion-de-activacion-relu-span">
     <span style="color:#4CC9F0">
      Evitando que los  gradientes desaparezcan mediante el uso de la función de activación ReLU
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-ventaja-de-la-funcion-de-activacion-relu-span">
       <span style="color:#4CC9F0">
        Ventaja de la función de activación ReLU
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-extensiones-y-alternativas-para-relu-span">
       <span style="color:#4CC9F0">
        Extensiones y alternativas para ReLU
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-relu-parametrizada-prelu-2015-span">
     <span style="color:#4CC9F0">
      ReLU parametrizada (PReLu), 2015
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-elu-2016-span">
       <span style="color:#4CC9F0">
        Función de activación Elu, 2016
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

    </nav>
</div>
    </div>
    <div class="article row">
        <div class="col pl-md-3 pl-lg-5 content-container">
            <!-- Table of contents that is only displayed when printing the page -->
            <div id="jb-print-docs-body" class="onlyprint">
                <h1><span style="color:#F72585">Funciones de Activación</span></h1>
                <!-- Table of contents -->
                <div id="print-main-content">
                    <div id="jb-print-toc">
                        
                        <div>
                            <h2> Contents </h2>
                        </div>
                        <nav aria-label="Page">
                            <ul class="visible nav section-nav flex-column">
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-introduccion-span">
   <span style="color:#4361EE">
    Introducción
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-por-que-necesitamos-funciones-de-activacion-span">
     <span style="color:#4CC9F0">
      ¿Por qué necesitamos funciones de activación?
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-funciones-de-activacion-clasicas-span">
   <span style="color:#4361EE">
    Funciones de activación clásicas
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-step-span">
     <span style="color:#4CC9F0">
      Función Step
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-activacion-lineal-span">
     <span style="color:#4CC9F0">
      Activación lineal
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funciones-de-activacion-tipo-sigmoide-span">
     <span style="color:#4CC9F0">
      Funciones de activación tipo sigmoide
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-logistica-sigmoid-span">
       <span style="color:#4CC9F0">
        Función logística (sigmoid)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-ejercicio-span">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-tangente-hiperbolica-span">
       <span style="color:#4CC9F0">
        Función de activacion Tangente hiperbólica
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id1">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-unidad-de-rectificacion-lineal-relu-span">
       <span style="color:#4CC9F0">
        Función de activación Unidad de rectificación lineal (ReLu)
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id2">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-softmax-span">
       <span style="color:#4CC9F0">
        Función de activación Softmax
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#id3">
       <span style="color:#4CC9F0">
        Ejercicio
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-seleccionando-una-funcion-de-activacion-span">
     <span style="color:#4CC9F0">
      Seleccionando una función de activación
     </span>
    </a>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-estado-del-arte-variaciones-de-la-funcion-de-activacion-de-relu-span">
   <span style="color:#4361EE">
    Estado del arte. Variaciones de la función de activación de ReLu
   </span>
  </a>
  <ul class="nav section-nav flex-column">
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-limitaciones-de-las-funciones-de-activacion-sigmoide-y-tanh-span">
     <span style="color:#4CC9F0">
      Limitaciones de las funciones de activación sigmoide y Tanh
     </span>
    </a>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-evitando-que-los-gradientes-desaparezcan-mediante-el-uso-de-la-funcion-de-activacion-relu-span">
     <span style="color:#4CC9F0">
      Evitando que los  gradientes desaparezcan mediante el uso de la función de activación ReLU
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-ventaja-de-la-funcion-de-activacion-relu-span">
       <span style="color:#4CC9F0">
        Ventaja de la función de activación ReLU
       </span>
      </a>
     </li>
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-extensiones-y-alternativas-para-relu-span">
       <span style="color:#4CC9F0">
        Extensiones y alternativas para ReLU
       </span>
      </a>
     </li>
    </ul>
   </li>
   <li class="toc-h3 nav-item toc-entry">
    <a class="reference internal nav-link" href="#span-style-color-4cc9f0-relu-parametrizada-prelu-2015-span">
     <span style="color:#4CC9F0">
      ReLU parametrizada (PReLu), 2015
     </span>
    </a>
    <ul class="nav section-nav flex-column">
     <li class="toc-h4 nav-item toc-entry">
      <a class="reference internal nav-link" href="#span-style-color-4cc9f0-funcion-de-activacion-elu-2016-span">
       <span style="color:#4CC9F0">
        Función de activación Elu, 2016
       </span>
      </a>
     </li>
    </ul>
   </li>
  </ul>
 </li>
 <li class="toc-h2 nav-item toc-entry">
  <a class="reference internal nav-link" href="#span-style-color-4361ee-referencias-span">
   <span style="color:#4361EE">
    Referencias
   </span>
  </a>
 </li>
</ul>

                        </nav>
                    </div>
                </div>
            </div>
            <main id="main-content" role="main">
                
              <div>
                
  <section class="tex2jax_ignore mathjax_ignore" id="span-style-color-f72585-funciones-de-activacion-span">
<h1><span style="color:#F72585">Funciones de Activación</span><a class="headerlink" href="#span-style-color-f72585-funciones-de-activacion-span" title="Enlazar permanentemente con este título">#</a></h1>
<section id="span-style-color-4361ee-introduccion-span">
<h2><span style="color:#4361EE">Introducción</span><a class="headerlink" href="#span-style-color-4361ee-introduccion-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>Como vimos anteriormente, la red neuronal tiene neuronas que trabajan en consonancia con sus pesos, su sesgo y su respectiva función de activación. En el modo de entrenamiento, se actualizan los pesos y sesgos de las neuronas sobre la base del error en la salida. Este proceso se conoce como <code class="docutils literal notranslate"><span class="pre">retropropagación</span></code> (backpropagation). Las funciones de activación permiten la retropropagación y los gradientes se suministran junto con el error para actualizar los pesos y sesgos.</p>
<p>La función de activación de un nodo define la salida de ese nodo dada una entrada o un conjunto de entradas. La función de activación decide si una neurona debe activarse o no calculando la suma ponderada y agregando más sesgo con ella.</p>
<p><strong>El propósito de la función de activación es introducir no linealidad en la salida de una neurona</strong>.</p>
<section id="span-style-color-4cc9f0-por-que-necesitamos-funciones-de-activacion-span">
<h3><span style="color:#4CC9F0">¿Por qué necesitamos funciones de activación? </span><a class="headerlink" href="#span-style-color-4cc9f0-por-que-necesitamos-funciones-de-activacion-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>Una red neuronal sin una función de activación es esencialmente un modelo de regresión lineal clásico. La función de activación realiza la transformación no lineal de la entrada, lo que la hace capaz de aprender y realizar tareas más complejas.</p>
</section>
</section>
<section id="span-style-color-4361ee-funciones-de-activacion-clasicas-span">
<h2><span style="color:#4361EE">Funciones de activación clásicas</span><a class="headerlink" href="#span-style-color-4361ee-funciones-de-activacion-clasicas-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>En la entrada, una neurona artificial calcula una «suma ponderada» de su entrada y agrega un sesgo. Como antes, sea <span class="math notranslate nohighlight">\( z = \sum_i x_iw_i + b \)</span>, <span class="math notranslate nohighlight">\( z  \in \mathcal {R} \)</span>. Una vez calculado el valor <span class="math notranslate nohighlight">\( z \)</span>, la neurona artificial decide si se debe «disparar» o no, basándose en el valor de <span class="math notranslate nohighlight">\( z \)</span>.</p>
<section id="span-style-color-4cc9f0-funcion-step-span">
<h3><span style="color:#4CC9F0">Función Step</span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-step-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>Lo primero que nos viene a la mente es ¿qué tal una función de activación basada en umbrales? Si el valor de <span class="math notranslate nohighlight">\( z \)</span> está por encima de cierto valor, declare que se ha <code class="docutils literal notranslate"><span class="pre">activado</span></code>. Si es menor que el umbral, diga que no.
El umbral más común es 0. La <em>función de activación Step</em> se define como</p>
<div class="math notranslate nohighlight">
\[\begin{split}
f(x) = Step(x) \begin{cases}
1, &amp;\text{ if } x \ge 0,\\
0, &amp;\text{ en otro caso }
\end{cases}
\end{split}\]</div>
<p>Observe la figura 1. Obviamente, <span class="math notranslate nohighlight">\(f'(x) = 0\)</span> for <span class="math notranslate nohighlight">\(x\ne 0\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="n">x</span> <span class="o">=</span> <span class="p">(</span><span class="o">-</span><span class="mi">10</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span> <span class="mi">10</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">0</span><span class="p">,</span><span class="mi">1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">step</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="n">where</span><span class="o">=</span><span class="s1">&#39;pre&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="p">,</span> <span class="s1">&#39;C0o&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_9_0.png" src="../../_images/Activation_Functions_9_0.png" />
</div>
</div>
<p><strong>Figura 1.</strong> <em>Función de activación Step.</em></p>
</section>
<section id="span-style-color-4cc9f0-activacion-lineal-span">
<h3><span style="color:#4CC9F0">Activación lineal</span><a class="headerlink" href="#span-style-color-4cc9f0-activacion-lineal-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>La función de activación lineal está definida por <span class="math notranslate nohighlight">\( f (x) = ax \)</span>. Tenga en cuenta que <span class="math notranslate nohighlight">\( f '(x) = a \)</span>, para todos <span class="math notranslate nohighlight">\( x \in \mathcal {R} \)</span>. Tenga en cuenta que <span class="math notranslate nohighlight">\( - \infty \le f (x) \le \infty \)</span>.</p>
<p>La función de activación lineal se utiliza en un solo lugar, es decir, la capa de salida. El efecto de esta función de activación es simplemente escalar los valores provenientes de la última capa oculta, para que se ajusten a los valores objetivo.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">y</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">x</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="s1">&#39;-r&#39;</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s1">&#39;y=2x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Graph of the linear activation function y=2x&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">xlabel</span><span class="p">(</span><span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#1C2833&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">ylabel</span><span class="p">(</span><span class="s1">&#39;y&#39;</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s1">&#39;#1C2833&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_13_0.png" src="../../_images/Activation_Functions_13_0.png" />
</div>
</div>
<p><strong>Figure 4.</strong> Linear activation function</p>
</section>
<section id="span-style-color-4cc9f0-funciones-de-activacion-tipo-sigmoide-span">
<h3><span style="color:#4CC9F0">Funciones de activación tipo sigmoide</span><a class="headerlink" href="#span-style-color-4cc9f0-funciones-de-activacion-tipo-sigmoide-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>Son funciones cuyo gráfico tiene una  forma de «S» alargada. Hay varios tipos de funciones sigmoideas. Las más utilizadas son las funciones logísticas y tangentes hiperbólicas.</p>
<section id="span-style-color-4cc9f0-funcion-logistica-sigmoid-span">
<h4><span style="color:#4CC9F0">Función logística (sigmoid)</span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-logistica-sigmoid-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>Esta función es definida por</p>
<div class="math notranslate nohighlight">
\[
f(x) = sigmoid(x) =\frac{1}{{1+ e^{-x}}},
\]</div>
<p>para <span class="math notranslate nohighlight">\(x\in \mathcal{R}\)</span>.</p>
</section>
<section id="span-style-color-4cc9f0-ejercicio-span">
<h4><span style="color:#4CC9F0">Ejercicio</span><a class="headerlink" href="#span-style-color-4cc9f0-ejercicio-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>Verifique que</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(0 \le f(x)\le 1\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(f'(x)= f(x)*(1-f(x))\)</span></p></li>
</ol>
<p>Por lo general, <span class="math notranslate nohighlight">\( f (x) \)</span> se usa en la capa de salida de una clasificación binaria, donde el resultado es 0 o 1, ya que el valor de la función sigmoidea se encuentra entre 0 y 1, por lo que el resultado se puede predecir fácilmente como 1 si el valor es mayor. que 0,5 y 0 en caso contrario.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">logistic</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="n">x</span><span class="p">)))</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Graph of the logistic activation function&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">logistic</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_22_0.png" src="../../_images/Activation_Functions_22_0.png" />
</div>
</div>
</section>
<section id="span-style-color-4cc9f0-funcion-de-activacion-tangente-hiperbolica-span">
<h4><span style="color:#4CC9F0">Función de activacion Tangente hiperbólica</span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-de-activacion-tangente-hiperbolica-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>La activación que funciona casi siempre mejor que la función sigmoidea es la función <em>tanh</em> también conocida como función tangente hiperbólica . En realidad, es una versión matemáticamente modificada de la función sigmoidea. Ambos son similares y pueden obtenerse una de la otra entre sí.</p>
<p>La función <em>Tanh</em> está definida por</p>
<div class="math notranslate nohighlight">
\[
f(x) = tanh(x) = \frac{2}{{1+ e^{-2x}}}-1,
\]</div>
<p>para  <span class="math notranslate nohighlight">\(x\in \mathcal{R}\)</span>.</p>
</section>
<section id="id1">
<h4><span style="color:#4CC9F0">Ejercicio</span><a class="headerlink" href="#id1" title="Enlazar permanentemente con este título">#</a></h4>
<p>Verifique que</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(-1 \le f(x)\le 1\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(f'(x)= 1 -f(x)^2\)</span>.</p></li>
<li><p><span class="math notranslate nohighlight">\(tanh(x) = 2 sigmoid(2x) -1\)</span>.</p></li>
</ol>
<p>Tanh se usa generalmente en capas ocultas de una red neuronal, ya que sus valores se encuentran entre -1 a 1, por lo que la media de la capa oculta resulta ser 0 o muy cerca de ella,  lo que ayuda a centrar los datos al acercar la media a 0. Esto facilita mucho el aprendizaje de la siguiente capa.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="k">def</span> <span class="nf">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">2</span><span class="o">/</span><span class="p">(</span><span class="mi">1</span><span class="o">+</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">(</span><span class="o">-</span><span class="mi">2</span><span class="o">*</span><span class="n">x</span><span class="p">))</span><span class="o">-</span><span class="mi">1</span><span class="p">)</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Graph of the tanget hyperbolic activation function&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">tanh</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_28_0.png" src="../../_images/Activation_Functions_28_0.png" />
</div>
</div>
</section>
<section id="span-style-color-4cc9f0-funcion-de-activacion-unidad-de-rectificacion-lineal-relu-span">
<h4><span style="color:#4CC9F0">Función de activación Unidad de rectificación lineal (ReLu)</span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-de-activacion-unidad-de-rectificacion-lineal-relu-span" title="Enlazar permanentemente con este título">#</a></h4>
<p><em>ReLu</em> es la función de activación más utilizada actualmente. Implementada principalmente en capas ocultas de la red neuronal. <em>ReLu</em> se define como</p>
<div class="math notranslate nohighlight">
\[
f(x) = ReLu(x) = max(0,x),
\]</div>
<p>para <span class="math notranslate nohighlight">\(x\in \mathcal{R}\)</span>.</p>
</section>
<section id="id2">
<h4><span style="color:#4CC9F0">Ejercicio</span><a class="headerlink" href="#id2" title="Enlazar permanentemente con este título">#</a></h4>
<p>Verifique que</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(0\le f(x)&lt; \infty\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(f'(x)= 1\)</span> for <span class="math notranslate nohighlight">\(x &gt; 0\)</span>, and  <span class="math notranslate nohighlight">\(f'(x)= 0\)</span> for <span class="math notranslate nohighlight">\(x &lt; 0\)</span>.</p></li>
</ol>
<p><em>ReLu</em> es menos costosa computacionalmente que <em>Tanh</em> y <em>sigmoide</em> porque involucra operaciones matemáticas más simples. A la vez, solamente se activan unas pocas neuronas, lo que hace que la red sea dispersa, lo que la hace eficiente y fácil de calcular. En palabras simples, <em>ReLu</em> permite a la red aprender mucho más rápido que la funciones <em>sigmoide</em> y <em>Tanh</em>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">Relu</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
    <span class="n">y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([[</span><span class="n">y</span><span class="p">],[</span><span class="n">x</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Graph of the Relu activation function&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">Relu</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_33_0.png" src="../../_images/Activation_Functions_33_0.png" />
</div>
</div>
</section>
<section id="span-style-color-4cc9f0-funcion-de-activacion-softmax-span">
<h4><span style="color:#4CC9F0">Función de activación Softmax </span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-de-activacion-softmax-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>La función softmax también es un tipo de función sigmoidea, pero es útil cuando intentamos manejar problemas de clasificación.</p>
<p>Generalmente se usa cuando se intenta manejar múltiples clases. La función softmax comprime las salidas para cada clase a valores entre 0 y 1 al dividir cada valor por la suma de las salidas (modificadas mediante una función exponencial).</p>
<p>La función softmax se usa idealmente en la capa de salida del clasificador donde realmente estamos tratando de alcanzar las probabilidades para definir la categoría que corresponde de cada entrada. Formalmente la función softmax es definida como sigue-</p>
<p>Sea <span class="math notranslate nohighlight">\(x=(x_1,\ldots,x_n)^t \in \mathbb{R}^n\)</span>. Softmax es una función <span class="math notranslate nohighlight">\(S: \mathbb{R}^n \to \mathbb{R}^n\)</span> definida por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
S(x) : \begin{pmatrix} x_1 \\ \vdots \\x_n\\ \end{pmatrix}    \to \begin{pmatrix} S_1 \\ \vdots \\S_n\\ \end{pmatrix}
\end{split}\]</div>
<p>en donde</p>
<div class="math notranslate nohighlight">
\[
S_j = \frac{e^{x_j}}{\sum_{k=1}^N e^{x_k}}.
\]</div>
<p>Dado que <span class="math notranslate nohighlight">\( S \)</span> es una función vectorial de <span class="math notranslate nohighlight">\( \mathbb {R} ^ n \)</span> a <span class="math notranslate nohighlight">\( \mathbb {R} ^ n \)</span>, la derivada es la matriz jacobiana dada por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
DS = \begin{pmatrix} D_1 S_1 &amp;\cdots&amp; D_1S_n\\
                     \cdots &amp; \ddots &amp; \cdots\\
                     D_n S_1 &amp; \cdots &amp; D_n S_n
     \end{pmatrix} 
\end{split}\]</div>
<p>Luego de unos simples cálculos se llega a que</p>
<div class="math notranslate nohighlight">
\[
D_j S_i =  S_i(\delta_{ij}-S_j),
\]</div>
<p>en donde  <span class="math notranslate nohighlight">\(\delta_{ij}\)</span> es llamado el delta de Kroneker definido por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\delta_{ij} = \begin{cases} 1, &amp;\text{si } i=j\\
                            0, &amp; \text{isi } i\ne j
               \end{cases}              
\end{split}\]</div>
<p>El siguiente fragmento de código muestra cómo implementar <span class="math notranslate nohighlight">\( DS \)</span> en Python</p>
</section>
<section id="id3">
<h4><span style="color:#4CC9F0">Ejercicio</span><a class="headerlink" href="#id3" title="Enlazar permanentemente con este título">#</a></h4>
<p>Verifique la ecuación anterior.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># derivative (grad) of the softmax function</span>
<span class="k">def</span> <span class="nf">softmax_grad</span><span class="p">(</span><span class="n">s</span><span class="p">):</span>
    <span class="c1"># input s is softmax value of the original input x. Its shape is (1,n) </span>
    <span class="c1"># i.e.  s = np.array([0.3,0.7]),  x = np.array([0,1])</span>

    <span class="c1"># make the matrix whose size is n^2.</span>
    <span class="n">jacobian_m</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jacobian_m</span><span class="p">)):</span>
        <span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">jacobian_m</span><span class="p">)):</span>
            <span class="k">if</span> <span class="n">i</span> <span class="o">==</span> <span class="n">j</span><span class="p">:</span>
                <span class="n">jacobian_m</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">])</span>
            <span class="k">else</span><span class="p">:</span> 
                <span class="n">jacobian_m</span><span class="p">[</span><span class="n">i</span><span class="p">][</span><span class="n">j</span><span class="p">]</span> <span class="o">=</span> <span class="o">-</span><span class="n">s</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">*</span> <span class="n">s</span><span class="p">[</span><span class="n">j</span><span class="p">]</span>
    <span class="k">return</span> <span class="n">jacobian_m</span>

<span class="c1"># testing the function</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">scipy.special</span>


<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">])</span>
<span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
<span class="n">softmax_grad</span><span class="p">(</span><span class="n">scipy</span><span class="o">.</span><span class="n">special</span><span class="o">.</span><span class="n">softmax</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.19661193, -0.19661193],
       [-0.19661193,  0.19661193]])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="span-style-color-4cc9f0-seleccionando-una-funcion-de-activacion-span">
<h3><span style="color:#4CC9F0">Seleccionando una función de activación</span><a class="headerlink" href="#span-style-color-4cc9f0-seleccionando-una-funcion-de-activacion-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>La <code class="docutils literal notranslate"><span class="pre">regla</span> <span class="pre">básica</span> <span class="pre">de</span> <span class="pre">combate</span></code> es que si realmente no sabe qué función de activación usar, simplemente use RELU, ya que es una función de activación general y se usa en la mayoría de los casos en estos días.
Si su salida es para clasificación binaria, la función sigmoidea es una elección muy natural para la capa de salida.</p>
</section>
</section>
<section id="span-style-color-4361ee-estado-del-arte-variaciones-de-la-funcion-de-activacion-de-relu-span">
<h2><span style="color:#4361EE">Estado del arte. Variaciones de la función de activación de ReLu</span><a class="headerlink" href="#span-style-color-4361ee-estado-del-arte-variaciones-de-la-funcion-de-activacion-de-relu-span" title="Enlazar permanentemente con este título">#</a></h2>
<p>En una red neuronal, la función de activación es responsable de transformar la entrada ponderada sumada del nodo en la activación del nodo o salida para esa entrada.</p>
<p>La función de activación <em>ReLU</em> es una función lineal por partes que tiene como salida a la entrada directamente si es positiva; de lo contrario, dará salida a cero. Se ha convertido en la función de activación predeterminada para muchos tipos de redes neuronales porque un modelo que la usa es más fácil de entrenar y, a menudo, logra un mejor rendimiento.En una red neuronal, la función de activación es responsable de transformar la entrada de pesos desde el nodo en la activación de la salida del nodo para dicha entrada.</p>
<section id="span-style-color-4cc9f0-limitaciones-de-las-funciones-de-activacion-sigmoide-y-tanh-span">
<h3><span style="color:#4CC9F0">Limitaciones de las funciones de activación sigmoide y Tanh</span><a class="headerlink" href="#span-style-color-4cc9f0-limitaciones-de-las-funciones-de-activacion-sigmoide-y-tanh-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>Se prefieren las funciones de activación no lineales, ya que permiten que los nodos aprendan estructuras más complejas en los datos. Tradicionalmente, dos funciones de activación no lineales ampliamente utilizadas son las funciones de activación tangente sigmoidea e hiperbólica.</p>
<p>Un problema general con las funciones <em>sigmoide</em> y <em>Tanh</em> es que <em>saturan</em> en los extremos. Esto significa que los valores grandes se ajustan a 1 y los valores pequeños a -1 (Tanh) o 0 (sigmoide) respectivamente. Además, las funciones solo son realmente sensibles a los cambios alrededor del punto medio de su entrada, como 0.5 para sigmoide y 0.0 para Tanh.</p>
<p>La sensibilidad y saturación limitadas de la función ocurren independientemente de si la activación sumada del nodo proporcionado como entrada contiene información útil o no. Una vez saturado, se vuelve un desafío para el algoritmo de aprendizaje seguir adaptando los pesos para mejorar el rendimiento del modelo.</p>
<p><span class="math notranslate nohighlight">\( \to\)</span> Las unidades sigmoidales se saturan en la mayor parte de su dominio: se saturan a un valor alto cuando <span class="math notranslate nohighlight">\( z \)</span> es muy positivo, se saturan a un valor bajo cuando <span class="math notranslate nohighlight">\( z \)</span> es muy negativo y solo son muy sensibles a su entrada cuando z está cerca de 0.</p>
<p>Finalmente, a medida que la capacidad del hardware aumentó con el uso de las GPU, las redes neuronales muy profundas que utilizan funciones de activación sigmoidea y tanh, no se pueden entrenar fácilmente.</p>
<p>Las capas profundas en redes grandes que utilizan estas funciones de activación no lineales no reciben información de gradiente útil. El error que se propaga a través de la red y que se usa para actualizar los peso hace que el gradiente de la red sufra de unp de dos problemas.</p>
<ul class="simple">
<li><p>Tiende a ser cero (el gradiente se desvanece).</p></li>
<li><p>Tiende a ser infinito (el gradiente explota).</p></li>
</ul>
<p>Los gradientes que desvanencen o que explotan hacen que sea difícil saber en qué dirección deben moverse los parámetros para mejorar la función de pérdida.</p>
</section>
<section id="span-style-color-4cc9f0-evitando-que-los-gradientes-desaparezcan-mediante-el-uso-de-la-funcion-de-activacion-relu-span">
<h3><span style="color:#4CC9F0">Evitando que los  gradientes desaparezcan mediante el uso de la función de activación ReLU</span><a class="headerlink" href="#span-style-color-4cc9f0-evitando-que-los-gradientes-desaparezcan-mediante-el-uso-de-la-funcion-de-activacion-relu-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>Para utilizar el descenso de gradiente estocástico con retropropagación de errores para entrenar redes neuronales profundas, se necesita <code class="docutils literal notranslate"><span class="pre">una</span> <span class="pre">función</span> <span class="pre">de</span> <span class="pre">activación</span> <span class="pre">que</span> <span class="pre">se</span> <span class="pre">vea</span> <span class="pre">y</span> <span class="pre">actúe</span> <span class="pre">como</span> <span class="pre">una</span> <span class="pre">función</span> <span class="pre">lineal</span></code>, pero que sea, de hecho, una función no lineal que permita aprender relaciones complejas en los datos.</p>
<p>La función también debe proporcionar más sensibilidad a la entrada de suma de activación y evitar una fácil saturación.</p>
<p>La solución había estado dando vueltas en el campo durante algún tiempo, aunque no se destacó hasta que algunos artículos de 2009 y 2011 arrojaron luz sobre ella.</p>
<p>La solución es utilizar la <strong>función de activación lineal rectificada</strong>, o <em>ReLU</em> para abreviar.</p>
<p>Un nodo o unidad que implementa esta función de activación se conoce como unidad de activación lineal rectificada, o ReLU. A menudo, las redes que utilizan la función rectificadora para las capas ocultas se denominan redes rectificadas.</p>
<p><span class="math notranslate nohighlight">\(\leadsto\)</span> La adopción de ReLU puede considerarse fácilmente <strong>uno de los pocos hitos en la revolución del aprendizaje profundo</strong>, p. ej. las técnicas que ahora permiten el desarrollo rutinario de redes neuronales muy profundas.</p>
<p>Debido a que las unidades lineales rectificadas son casi lineales, conservan muchas de las propiedades que hacen que los modelos lineales sean fáciles de optimizar con métodos basados en gradientes. También conservan muchas de las propiedades que hacen que los modelos lineales generalicen bien.</p>
<section id="span-style-color-4cc9f0-ventaja-de-la-funcion-de-activacion-relu-span">
<h4><span style="color:#4CC9F0">Ventaja de la función de activación ReLU</span><a class="headerlink" href="#span-style-color-4cc9f0-ventaja-de-la-funcion-de-activacion-relu-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>La función de activación lineal rectificada se ha convertido rápidamente en la función de activación predeterminada al desarrollar la mayoría de los tipos de redes neuronales.</p>
<p>Como tal, es importante tomarse un momento para revisar algunos de los beneficios del enfoque, destacados por primera vez por Xavier Glorot, et al. en su documento histórico de 2012 sobre el uso de ReLU titulado <a class="reference external" href="https://proceedings.mlr.press/v15/glorot11a/glorot11a.pdf">Deep Sparse Rectifier Neural Networks</a>.</p>
<ol class="simple">
<li><p><strong>Simplicidad computacional</strong>. La función del rectificador es trivial de implementar y requiere una función max(). Esto es diferente a la función de activación sigmoidea y tanh que requieren el uso de un cálculo exponencial.</p></li>
<li><p><strong>Escasa representación</strong>. Un beneficio importante de la función de rectificador es que es capaz de generar un valor cero verdadero. Esto es diferente a las funciones de activación tanh y sigmoidea que aprenden a aproximarse a una salida muy cercana a cero, pero no un verdadero valor cero. Esto significa que las entradas negativas pueden generar valores cero verdaderos, lo que permite la activación de capas ocultas en redes neuronales para contener uno o más valores cero verdaderos. Esto se denomina representación dispersa y es una propiedad deseable en el aprendizaje representacional, ya que puede acelerar el aprendizaje y simplificar el modelo.</p></li>
<li><p><strong>Comportamiento lineal</strong>. La función rectificadora se ve y actúa principalmente como una función de activación lineal. En general, una red neuronal es más fácil de optimizar cuando su comportamiento es lineal o casi lineal.</p></li>
<li><p><strong>Entrene redes profundas</strong>. Es importante destacar que el (re) descubrimiento y la adopción de la función de activación lineal rectificada significó que se hizo posible explotar las mejoras en el hardware y entrenar con éxito redes profundas de múltiples capas con una función de activación no lineal mediante retropropagación.</p></li>
</ol>
</section>
<section id="span-style-color-4cc9f0-extensiones-y-alternativas-para-relu-span">
<h4><span style="color:#4CC9F0">Extensiones y alternativas para ReLU</span><a class="headerlink" href="#span-style-color-4cc9f0-extensiones-y-alternativas-para-relu-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>El ReLU tiene algunas limitaciones. Una de las principales limitaciones de ReLU es el caso en el que las actualizaciones de gran peso pueden significar que la entrada sumada a la función de activación es siempre negativa, independientemente de la entrada a la red.</p>
<p>Esto significa que un nodo con este problema siempre generará un valor de activación de 0.0. Esto se conoce como un «ReLU moribundo».</p>
<p>Algunas extensiones populares de ReLU relajan la salida no lineal de la función para permitir pequeños valores negativos de alguna manera.</p>
</section>
</section>
<section id="span-style-color-4cc9f0-relu-parametrizada-prelu-2015-span">
<h3><span style="color:#4CC9F0">ReLU parametrizada (PReLu), 2015</span><a class="headerlink" href="#span-style-color-4cc9f0-relu-parametrizada-prelu-2015-span" title="Enlazar permanentemente con este título">#</a></h3>
<p>La función de activación PRelu es definida por</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
f(y_i) = \begin{cases} y_i, &amp; \text{ si } y_i &gt; 0\\
a_i y_i, &amp; \text{ if } y_i \le 0 \end{cases}
\end{equation}
\end{split}\]</div>
<p>Aquí <span class="math notranslate nohighlight">\( y_i \)</span> es la entrada de la activación no lineal <span class="math notranslate nohighlight">\( f \)</span> en el <span class="math notranslate nohighlight">\( i \)</span> -ésimo
canal, y <span class="math notranslate nohighlight">\( a_i \)</span> es un coeficiente que controla la pendiente del
parte negativa. El subíndice i en ai indica que permitimos
la activación no lineal para variar en diferentes canales.</p>
<p>Observe que</p>
<ol class="simple">
<li><p><span class="math notranslate nohighlight">\(f(y_i) = max(0,y_i) + a_i min(0,y_i)\)</span>
2.<span class="math notranslate nohighlight">\(
\begin{equation}
f'(y_i) = \begin{cases} 1, &amp; \text{ si } y_i &gt; 0\\
a_i , &amp; \text{ si } y_i \le 0 \end{cases}
\end{equation}
\)</span></p></li>
</ol>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">PRelu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([[</span><span class="n">y</span><span class="p">],[</span><span class="n">x</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="n">a</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([[</span><span class="n">y</span><span class="p">],[</span><span class="n">x</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="mf">0.2</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Graph of the PRelu activation function, a=0.2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">PRelu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_54_0.png" src="../../_images/Activation_Functions_54_0.png" />
</div>
</div>
<section id="span-style-color-4cc9f0-funcion-de-activacion-elu-2016-span">
<h4><span style="color:#4CC9F0">Función de activación Elu, 2016</span><a class="headerlink" href="#span-style-color-4cc9f0-funcion-de-activacion-elu-2016-span" title="Enlazar permanentemente con este título">#</a></h4>
<p>Elu es definida como</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{equation}
f(x) = \begin{cases} x, &amp; \text{ si } x &gt; 0\\
\alpha (\exp(x)-1), &amp; \text{ if } x \le 0 \end{cases}
\end{equation}
\end{split}\]</div>
<p>Observe que
$<span class="math notranslate nohighlight">\(
\begin{equation}
f'(x) = \begin{cases} 1, &amp; \text{ si } x &gt; 0\\
f(x)+\alpha, &amp; \text{ if } x \le 0 \end{cases}
\end{equation}
\)</span>$</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>

<span class="k">def</span> <span class="nf">Elu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="n">y</span><span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">([[</span><span class="n">y</span><span class="p">],[</span><span class="n">x</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span><span class="mi">0</span><span class="p">))</span> <span class="o">+</span> <span class="n">a</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">ndarray</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">([</span><span class="n">a</span><span class="o">*</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">exp</span><span class="p">([</span><span class="n">x</span><span class="p">])</span> <span class="o">-</span><span class="mi">1</span><span class="p">),[</span><span class="n">x</span><span class="p">]],</span> <span class="n">axis</span> <span class="o">=</span><span class="mi">0</span><span class="p">))</span>

<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="o">-</span><span class="mi">5</span><span class="p">,</span><span class="mi">5</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>
<span class="n">a</span> <span class="o">=</span> <span class="mf">1.0</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;Gráfica de la función de activación Elu, a=0.2&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">Elu</span><span class="p">(</span><span class="n">a</span><span class="p">,</span><span class="n">x</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="../../_images/Activation_Functions_57_0.png" src="../../_images/Activation_Functions_57_0.png" />
</div>
</div>
<p>La siguiente tabla tomada de <a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">Wikipedia</a> presenta las funciones de activación mas conocidas.</p>
<table class="wikitable sortable bs-exportable exportable">
<tbody><tr>
<th>Name
</th>
<th class="unsortable">Plot
</th>
<th>Function, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/202945cce41ecebb6f643f31d119c514bec7a074" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.418ex; height:2.843ex;" alt="f(x)"/></span>
</th>
<th><a href="/wiki/Derivative" title="Derivative">Derivative</a> of <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/132e57acb643253e7810ee9702d9581f159a1c61" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.671ex; width:1.279ex; height:2.509ex;" alt="f"/></span>, <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f'(x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>f</mi>
          <mo>&#x2032;</mo>
        </msup>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f'(x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/d0cd7d7c75340e779d82658e19d1720ce84ab127" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.144ex; height:3.009ex;" alt="f&#039;(x)"/></span>
</th>
<th><a href="/wiki/Interval_(mathematics)#Notations_for_intervals" title="Interval (mathematics)">Range</a>
</th>
<th><a href="/wiki/Smoothness#Order_of_continuity" title="Smoothness">Order of continuity</a>
</th></tr>
<tr>
<td><a href="/wiki/Identity_function" title="Identity function">Identity</a>
</td>
<td><a href="/wiki/File:Activation_identity.svg" class="image"><img alt="Activation identity.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Activation_identity.svg/120px-Activation_identity.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Activation_identity.svg/180px-Activation_identity.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/9/9e/Activation_identity.svg/240px-Activation_identity.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/87f9e315fd7e2ba406057a97300593c4802b53e4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.33ex; height:1.676ex;" alt="x"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 1}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>1</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 1}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/92d98b82a3778f043108d4e20960a9193df57cbf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.162ex; height:2.176ex;" alt="1"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-\infty ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-\infty ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c8c11c44279888c9e395eeb5f45d121348ae10a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.299ex; height:2.843ex;" alt="(-\infty ,\infty )"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td><a href="/wiki/Heaviside_step_function" title="Heaviside step function">Binary step</a>
</td>
<td><a href="/wiki/File:Activation_binary_step.svg" class="image"><img alt="Activation binary step.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Activation_binary_step.svg/120px-Activation_binary_step.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Activation_binary_step.svg/180px-Activation_binary_step.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4b/Activation_binary_step.svg/240px-Activation_binary_step.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/5620555e698f283ad8d1db03be0bb1ec5e3bba25" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:13.51ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}0&amp;{\text{if }}x\neq 0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2260;<!-- ≠ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>undefined</mtext>
                  </mrow>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}0&amp;{\text{if }}x\neq 0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/035155c3d067d90da5c17df00d70406d06e8c285" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:22.233ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}0&amp;{\text{if }}x\neq 0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \{0,1\}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo fence="false" stretchy="false">{</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <mo fence="false" stretchy="false">}</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \{0,1\}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/28de5781698336d21c9c560fb1cbb3fb406923eb" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.684ex; height:2.843ex;" alt="\{0,1\}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{-1}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <mn>1</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{-1}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/fbeead216a363d09a6d0a05e192bdc3e7ed1067f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:4.131ex; height:2.676ex;" alt="{\displaystyle C^{-1}}"/></span>
</td></tr>
<tr>
<td><a href="/wiki/Logistic_function" title="Logistic function">Logistic</a>, sigmoid, or soft<span class="nowrap">&#160;</span>step
</td>
<td><a href="/wiki/File:Activation_logistic.svg" class="image"><img alt="Activation logistic.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Activation_logistic.svg/120px-Activation_logistic.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Activation_logistic.svg/180px-Activation_logistic.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/5/5b/Activation_logistic.svg/240px-Activation_logistic.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \sigma (x)={\frac {1}{1+e^{-x}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03C3;<!-- σ --></mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \sigma (x)={\frac {1}{1+e^{-x}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b2a78e39c42d7d51c4041d142740a7719e55b314" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:15.941ex; height:5.509ex;" alt="{\displaystyle \sigma (x)={\frac {1}{1+e^{-x}}}}"/></span><sup class="reference plainlinks nourlexpansion" id="ref_logistic1"><a class="external autonumber" href="https://en.wikipedia.org/wiki/Activation_function#endnote_logistic1">[1]</a></sup>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle f(x)(1-f(x))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle f(x)(1-f(x))}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/4c31efde5f30f83edf924af9feb31f0eb59d1a98" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.647ex; height:2.843ex;" alt="{\displaystyle f(x)(1-f(x))}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (0,1)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (0,1)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c79c6838e423c1ed3c7ea532a56dc9f9dae8290b" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:5.168ex; height:2.843ex;" alt="(0,1)"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td>Hyperbolic tangent (<a href="/wiki/Hyperbolic_function#Hyperbolic_tangent" class="mw-redirect" title="Hyperbolic function">tanh</a>)
</td>
<td><a href="/wiki/File:Activation_tanh.svg" class="image"><img alt="Activation tanh.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Activation_tanh.svg/120px-Activation_tanh.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Activation_tanh.svg/180px-Activation_tanh.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/c/cb/Activation_tanh.svg/240px-Activation_tanh.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \tanh(x)={\frac {e^{x}-e^{-x}}{e^{x}+e^{-x}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>tanh</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>=</mo>
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>&#x2212;<!-- − --></mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
            <mrow>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \tanh(x)={\frac {e^{x}-e^{-x}}{e^{x}+e^{-x}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/f8e81902c8d71b06c246769bad0fe17c9cf1efd9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:20.357ex; height:5.843ex;" alt="{\displaystyle \tanh(x)={\frac {e^{x}-e^{-x}}{e^{x}+e^{-x}}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle 1-f(x)^{2}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mn>1</mn>
        <mo>&#x2212;<!-- − --></mo>
        <mi>f</mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <msup>
          <mo stretchy="false">)</mo>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>2</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle 1-f(x)^{2}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/2bb42f038020ac20689657ce6f6f683296554e1f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.475ex; height:3.176ex;" alt="{\displaystyle 1-f(x)^{2}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-1,1)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>1</mn>
        <mo>,</mo>
        <mn>1</mn>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-1,1)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e120a3bd60fc89b495dd7ef6039465b7e6a703b1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.976ex; height:2.843ex;" alt="(-1,1)"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td><a href="/wiki/Rectifier_(neural_networks)" title="Rectifier (neural networks)">Rectified linear unit</a> (ReLU)<sup id="cite_ref-9" class="reference"><a href="#cite_note-9">&#91;9&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_rectified_linear.svg" class="image"><img alt="Activation rectified linear.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/120px-Activation_rectified_linear.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/180px-Activation_rectified_linear.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_rectified_linear.svg/240px-Activation_rectified_linear.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}&amp;{\begin{cases}0&amp;{\text{if }}x\leq 0\\x&amp;{\text{if }}x&gt;0\end{cases}}\\{}={}&amp;\max\{0,x\}=x{\textbf {1}}_{x&gt;0}\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd />
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mrow>
                    <mo>{</mo>
                    <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
                      <mtr>
                        <mtd>
                          <mn>0</mn>
                        </mtd>
                        <mtd>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mtext>if&#xA0;</mtext>
                          </mrow>
                          <mi>x</mi>
                          <mo>&#x2264;<!-- ≤ --></mo>
                          <mn>0</mn>
                        </mtd>
                      </mtr>
                      <mtr>
                        <mtd>
                          <mi>x</mi>
                        </mtd>
                        <mtd>
                          <mrow class="MJX-TeXAtom-ORD">
                            <mtext>if&#xA0;</mtext>
                          </mrow>
                          <mi>x</mi>
                          <mo>&gt;</mo>
                          <mn>0</mn>
                        </mtd>
                      </mtr>
                    </mtable>
                    <mo fence="true" stretchy="true" symmetric="true"></mo>
                  </mrow>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>            &lt;/mrow&gt;
            &lt;mo&gt;=&lt;/mo&gt;
            &lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;

            &lt;/mrow&gt;
          &lt;/mtd&gt;
          &lt;mtd&gt;
            &lt;mi&gt;&lt;/mi&gt;
            &lt;mo movablelimits=&quot;true&quot; form=&quot;prefix&quot;&gt;max&lt;/mo&gt;
            &lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;{&lt;/mo&gt;
            &lt;mn&gt;0&lt;/mn&gt;
            &lt;mo&gt;,&lt;/mo&gt;
            &lt;mi&gt;x&lt;/mi&gt;
            &lt;mo fence=&quot;false&quot; stretchy=&quot;false&quot;&gt;}&lt;/mo&gt;
            &lt;mo&gt;=&lt;/mo&gt;
            &lt;mi&gt;x&lt;/mi&gt;
            &lt;msub&gt;
              &lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;
                &lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;
                  &lt;mtext mathvariant=&quot;bold&quot;&gt;1&lt;/mtext&gt;
                &lt;/mrow&gt;
              &lt;/mrow&gt;
              &lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;
                &lt;mi&gt;x&lt;/mi&gt;
                &lt;mo&gt;&amp;gt;&lt;/mo&gt;
                &lt;mn&gt;0&lt;/mn&gt;
              &lt;/mrow&gt;
            &lt;/msub&gt;
          &lt;/mtd&gt;
        &lt;/mtr&gt;
      &lt;/mtable&gt;
    &lt;/mrow&gt;
  &lt;/mstyle&gt;
&lt;/mrow&gt;
&lt;annotation encoding=&quot;application/x-tex&quot;&gt;{\displaystyle {\begin{aligned}&amp;amp;{\begin{cases}0&amp;amp;{\text{if }}x\leq 0\\x&amp;amp;{\text{if }}x&amp;gt;0\end{cases}}\\{}={}&amp;amp;\max\{0,x\}=x{\textbf {1}}_{x&amp;gt;0}\end{aligned}}}&lt;/annotation&gt;
</pre></div>
</div>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/281532984565d3931de1cd1edc6e006d59fc67f4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -4.005ex; width:23.452ex; height:9.176ex;" alt="{\displaystyle {\begin{aligned}&amp;{\begin{cases}0&amp;{\text{if }}x\leq 0\\x&amp;{\text{if }}x&gt;0\end{cases}}\\{}={}&amp;\max\{0,x\}=x{\textbf {1}}_{x&gt;0}\end{aligned}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>0</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&gt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>undefined</mtext>
                  </mrow>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7def1a8bcfe903e95398e0a77542b0b096dae3cf" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.671ex; width:22.556ex; height:8.509ex;" alt="{\displaystyle {\begin{cases}0&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\{\text{undefined}}&amp;{\text{if }}x=0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle [0,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">[</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle [0,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/8dc2d914c2df66bc0f7893bfb8da36766650fe47" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.072ex; height:2.843ex;" alt="[0,\infty )"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c14274cad45f7c22b662e7a4e56b1db052883d1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.852ex; height:2.676ex;" alt="C^0"/></span>
</td></tr>
<tr>
<td>Gaussian Error Linear Unit (GELU)<sup id="cite_ref-ReferenceA_4-1" class="reference"><a href="#cite_note-ReferenceA-4">&#91;4&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_gelu.png" class="image" title="Visualization of the Gaussian Error Linear Unit (GELU)"><img alt="Visualization of the Gaussian Error Linear Unit (GELU)" src="//upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Activation_gelu.png/120px-Activation_gelu.png" decoding="async" width="120" height="80" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Activation_gelu.png/180px-Activation_gelu.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/4/4e/Activation_gelu.png/240px-Activation_gelu.png 2x" data-file-width="1200" data-file-height="800" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{aligned}&amp;{\frac {1}{2}}x\left(1+{\text{erf}}\left({\frac {x}{\sqrt {2}}}\right)\right)\\{}={}&amp;x\Phi (x)\end{aligned}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mtable columnalign="right left right left right left right left right left right left" rowspacing="3pt" columnspacing="0em 2em 0em 2em 0em 2em 0em 2em 0em 2em 0em" displaystyle="true">
            <mtr>
              <mtd />
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
                  <mfrac>
                    <mn>1</mn>
                    <mn>2</mn>
                  </mfrac>
                </mrow>
                <mi>x</mi>
                <mrow>
                  <mo>(</mo>
                  <mrow>
                    <mn>1</mn>
                    <mo>+</mo>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mtext>erf</mtext>
                    </mrow>
                    <mrow>
                      <mo>(</mo>
                      <mrow class="MJX-TeXAtom-ORD">
                        <mfrac>
                          <mi>x</mi>
                          <msqrt>
                            <mn>2</mn>
                          </msqrt>
                        </mfrac>
                      </mrow>
                      <mo>)</mo>
                    </mrow>
                  </mrow>
                  <mo>)</mo>
                </mrow>
              </mtd>
            </mtr>
            <mtr>
              <mtd>
                <mrow class="MJX-TeXAtom-ORD">
<div class="highlight-none notranslate"><div class="highlight"><pre><span></span>            &lt;/mrow&gt;
            &lt;mo&gt;=&lt;/mo&gt;
            &lt;mrow class=&quot;MJX-TeXAtom-ORD&quot;&gt;

            &lt;/mrow&gt;
          &lt;/mtd&gt;
          &lt;mtd&gt;
            &lt;mi&gt;x&lt;/mi&gt;
            &lt;mi mathvariant=&quot;normal&quot;&gt;&amp;#x03A6;&lt;!-- Φ --&gt;&lt;/mi&gt;
            &lt;mo stretchy=&quot;false&quot;&gt;(&lt;/mo&gt;
            &lt;mi&gt;x&lt;/mi&gt;
            &lt;mo stretchy=&quot;false&quot;&gt;)&lt;/mo&gt;
          &lt;/mtd&gt;
        &lt;/mtr&gt;
      &lt;/mtable&gt;
    &lt;/mrow&gt;
  &lt;/mstyle&gt;
&lt;/mrow&gt;
&lt;annotation encoding=&quot;application/x-tex&quot;&gt;{\displaystyle {\begin{aligned}&amp;amp;{\frac {1}{2}}x\left(1+{\text{erf}}\left({\frac {x}{\sqrt {2}}}\right)\right)\\{}={}&amp;amp;x\Phi (x)\end{aligned}}}&lt;/annotation&gt;
</pre></div>
</div>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/36c937195a62f5db3de7bbadf3990d2356dd2470" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -4.171ex; width:25.388ex; height:9.509ex;" alt="{\displaystyle {\begin{aligned}&amp;{\frac {1}{2}}x\left(1+{\text{erf}}\left({\frac {x}{\sqrt {2}}}\right)\right)\\{}={}&amp;x\Phi (x)\end{aligned}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \Phi (x)+x\phi (x)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi mathvariant="normal">&#x03A6;<!-- Φ --></mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
        <mo>+</mo>
        <mi>x</mi>
        <mi>&#x03D5;<!-- ϕ --></mi>
        <mo stretchy="false">(</mo>
        <mi>x</mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \Phi (x)+x\phi (x)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/bb43f09e198e0ef8e01fa00096ef3008100531f5" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:13.512ex; height:2.843ex;" alt="{\displaystyle \Phi (x)+x\phi (x)}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-0.17\ldots ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>0.17</mn>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-0.17\ldots ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6c15eea6a98f95d0a273d74ac6a4d491bf279b44" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:14.607ex; height:2.843ex;" alt="{\displaystyle (-0.17\ldots ,\infty )}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td>Softplus<sup id="cite_ref-10" class="reference"><a href="#cite_note-10">&#91;10&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_softplus.svg" class="image"><img alt="Activation softplus.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Activation_softplus.svg/120px-Activation_softplus.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/7/72/Activation_softplus.svg/180px-Activation_softplus.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/7/72/Activation_softplus.svg/240px-Activation_softplus.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \ln \left(1+e^{x}\right)}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mrow>
          <mo>(</mo>
          <mrow>
            <mn>1</mn>
            <mo>+</mo>
            <msup>
              <mi>e</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mi>x</mi>
              </mrow>
            </msup>
          </mrow>
          <mo>)</mo>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \ln \left(1+e^{x}\right)}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a8cca29e3bdc9be84b90b9fcde7d23d9019cdc31" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:10.007ex; height:2.843ex;" alt="{\displaystyle \ln \left(1+e^{x}\right)}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {1}{1+e^{-x}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mn>1</mn>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {1}{1+e^{-x}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/a0730f7ecb26c15b341f9410687d23d0939977af" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:8.374ex; height:5.509ex;" alt="{\displaystyle {\frac {1}{1+e^{-x}}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (0,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (0,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/da17102e4ed0886686094ee531df040d2e86352a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:6.329ex; height:2.843ex;" alt="(0,\infty )"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td>Exponential linear unit (ELU)<sup id="cite_ref-11" class="reference"><a href="#cite_note-11">&#91;11&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_elu.svg" class="image"><img alt="Activation elu.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Activation_elu.svg/120px-Activation_elu.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Activation_elu.svg/180px-Activation_elu.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/b/bc/Activation_elu.svg/240px-Activation_elu.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}\alpha \left(e^{x}-1\right)&amp;{\text{if }}x\leq 0\\x&amp;{\text{if }}x&gt;0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                  <mrow>
                    <mo>(</mo>
                    <mrow>
                      <msup>
                        <mi>e</mi>
                        <mrow class="MJX-TeXAtom-ORD">
                          <mi>x</mi>
                        </mrow>
                      </msup>
                      <mo>&#x2212;<!-- − --></mo>
                      <mn>1</mn>
                    </mrow>
                    <mo>)</mo>
                  </mrow>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2264;<!-- ≤ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&gt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}\alpha \left(e^{x}-1\right)&amp;{\text{if }}x\leq 0\\x&amp;{\text{if }}x&gt;0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0f409bbcde02f828392ce0db27105ac46cc41477" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:22.29ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}\alpha \left(e^{x}-1\right)&amp;{\text{if }}x\leq 0\\x&amp;{\text{if }}x&gt;0\end{cases}}}"/></span>
<dl><dd>with parameter <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \alpha }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B1;<!-- α --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \alpha }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.488ex; height:1.676ex;" alt="\alpha "/></span></dd></dl>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\1&amp;{\text{if }}x=0{\text{ and }}\alpha =1\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                  <msup>
                    <mi>e</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>x</mi>
                    </mrow>
                  </msup>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&gt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>=</mo>
                  <mn>0</mn>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>&#xA0;and&#xA0;</mtext>
                  </mrow>
                  <mi>&#x03B1;<!-- α --></mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\1&amp;{\text{if }}x=0{\text{ and }}\alpha =1\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/928d2cf6b7b334bad1f3177cfa75202da302ee96" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.671ex; width:27.071ex; height:8.509ex;" alt="{\displaystyle {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x&gt;0\\1&amp;{\text{if }}x=0{\text{ and }}\alpha =1\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-\alpha ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03B1;<!-- α --></mi>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-\alpha ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/9a966cc9f5c4412bfc563ac9790d9ed43177bfdd" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:8.463ex; height:2.843ex;" alt="{\displaystyle (-\alpha ,\infty )}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}C^{1}&amp;{\text{if }}\alpha =1\\C^{0}&amp;{\text{otherwise}}\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <msup>
                    <mi>C</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>1</mn>
                    </mrow>
                  </msup>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>&#x03B1;<!-- α --></mi>
                  <mo>=</mo>
                  <mn>1</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <msup>
                    <mi>C</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mn>0</mn>
                    </mrow>
                  </msup>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>otherwise</mtext>
                  </mrow>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}C^{1}&amp;{\text{if }}\alpha =1\\C^{0}&amp;{\text{otherwise}}\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/98153cab376da330237e4a712fe848ae44dbced6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:17.246ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}C^{1}&amp;{\text{if }}\alpha =1\\C^{0}&amp;{\text{otherwise}}\end{cases}}}"/></span>
</td></tr>
<tr>
<td>Scaled exponential linear unit (SELU)<sup id="cite_ref-12" class="reference"><a href="#cite_note-12">&#91;12&#93;</a></sup>
</td>
<td>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lambda {\begin{cases}\alpha (e^{x}-1)&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BB;<!-- λ --></mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                  <mo stretchy="false">(</mo>
                  <msup>
                    <mi>e</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>x</mi>
                    </mrow>
                  </msup>
                  <mo>&#x2212;<!-- − --></mo>
                  <mn>1</mn>
                  <mo stretchy="false">)</mo>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lambda {\begin{cases}\alpha (e^{x}-1)&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b5f46708e4a264b8f1bb18b177b389c08e33c30f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:23.258ex; height:6.176ex;" alt="{\displaystyle \lambda {\begin{cases}\alpha (e^{x}-1)&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
<dl><dd>with parameters <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lambda =1.0507}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BB;<!-- λ --></mi>
        <mo>=</mo>
        <mn>1.0507</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lambda =1.0507}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/740e4b3506d22e67bfc7bfd3e995d53bb81b3327" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:10.913ex; height:2.176ex;" alt="{\displaystyle \lambda =1.0507}"/></span> and <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \alpha =1.67326}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B1;<!-- α --></mi>
        <mo>=</mo>
        <mn>1.67326</mn>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \alpha =1.67326}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/169a7cbcf6cf284fa0e53c32238fa079f5147325" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:12.208ex; height:2.176ex;" alt="{\displaystyle \alpha =1.67326}"/></span></dd></dl>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \lambda {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03BB;<!-- λ --></mi>
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                  <msup>
                    <mi>e</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mi>x</mi>
                    </mrow>
                  </msup>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \lambda {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/6e70f5d905524d91daaff606a6e7b409479ed6f9" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:17.446ex; height:6.176ex;" alt="{\displaystyle \lambda {\begin{cases}\alpha e^{x}&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-\lambda \alpha ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi>&#x03BB;<!-- λ --></mi>
        <mi>&#x03B1;<!-- α --></mi>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-\lambda \alpha ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e1357562409324a8c59d68435f87b4acb04d2045" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.818ex; height:2.843ex;" alt="{\displaystyle (-\lambda \alpha ,\infty )}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c14274cad45f7c22b662e7a4e56b1db052883d1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.852ex; height:2.676ex;" alt="C^0"/></span>
</td></tr>
<tr>
<td>Leaky rectified linear unit (Leaky ReLU)<sup id="cite_ref-13" class="reference"><a href="#cite_note-13">&#91;13&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_prelu.svg" class="image"><img alt="Activation prelu.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/120px-Activation_prelu.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/180px-Activation_prelu.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/240px-Activation_prelu.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}0.01x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>0.01</mn>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}0.01x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/ae7d94c8e173aa0a742c9d8cef64d6b64830926e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:17.811ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}0.01x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}0.01&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mn>0.01</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}0.01&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7d33d15f95972e19f5ab5c67cb0a596762fd8ada" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:16.481ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}0.01&amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-\infty ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-\infty ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c8c11c44279888c9e395eeb5f45d121348ae10a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.299ex; height:2.843ex;" alt="(-\infty ,\infty )"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c14274cad45f7c22b662e7a4e56b1db052883d1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.852ex; height:2.676ex;" alt="C^0"/></span>
</td></tr>
<tr>
<td>Parameteric rectified linear unit (PReLU)<sup id="cite_ref-14" class="reference"><a href="#cite_note-14">&#91;14&#93;</a></sup>
</td>
<td><a href="/wiki/File:Activation_prelu.svg" class="image"><img alt="Activation prelu.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/120px-Activation_prelu.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/180px-Activation_prelu.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/a/ae/Activation_prelu.svg/240px-Activation_prelu.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}\alpha x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mi>x</mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}\alpha x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/c3a5ba694377a9623afaec3b5356616242d3b98e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:15.164ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}\alpha x&amp;{\text{if }}x&lt;0\\x&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
<dl><dd>with parameter <span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle \alpha }">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>&#x03B1;<!-- α --></mi>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle \alpha }</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/b79333175c8b3f0840bfb4ec41b8072c83ea88d3" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:1.488ex; height:1.676ex;" alt="\alpha "/></span></dd></dl>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\begin{cases}\alpha &amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mrow>
            <mo>{</mo>
            <mtable columnalign="left left" rowspacing=".2em" columnspacing="1em" displaystyle="false">
              <mtr>
                <mtd>
                  <mi>&#x03B1;<!-- α --></mi>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&lt;</mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
              <mtr>
                <mtd>
                  <mn>1</mn>
                </mtd>
                <mtd>
                  <mrow class="MJX-TeXAtom-ORD">
                    <mtext>if&#xA0;</mtext>
                  </mrow>
                  <mi>x</mi>
                  <mo>&#x2265;<!-- ≥ --></mo>
                  <mn>0</mn>
                </mtd>
              </mtr>
            </mtable>
            <mo fence="true" stretchy="true" symmetric="true"></mo>
          </mrow>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\begin{cases}\alpha &amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e18e0768b83bced2a28b7bea9937939e66323dd7" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.505ex; width:13.835ex; height:6.176ex;" alt="{\displaystyle {\begin{cases}\alpha &amp;{\text{if }}x&lt;0\\1&amp;{\text{if }}x\geq 0\end{cases}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (-\infty ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (-\infty ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/0c8c11c44279888c9e395eeb5f45d121348ae10a" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:9.299ex; height:2.843ex;" alt="(-\infty ,\infty )"/></span><sup class="reference plainlinks nourlexpansion" id="ref_alpha"><a class="external autonumber" href="https://en.wikipedia.org/wiki/Activation_function#endnote_alpha">[2]</a></sup>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{0}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mn>0</mn>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{0}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7c14274cad45f7c22b662e7a4e56b1db052883d1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:2.852ex; height:2.676ex;" alt="C^0"/></span>
</td></tr>
<tr>
<td>Sigmoid linear unit (SiLU,<sup id="cite_ref-ReferenceA_4-2" class="reference"><a href="#cite_note-ReferenceA-4">&#91;4&#93;</a></sup> Sigmoid shrinkage,<sup id="cite_ref-refssbs1_15-0" class="reference"><a href="#cite_note-refssbs1-15">&#91;15&#93;</a></sup> SiL,<sup id="cite_ref-16" class="reference"><a href="#cite_note-16">&#91;16&#93;</a></sup> or Swish-&#8205;1<sup id="cite_ref-17" class="reference"><a href="#cite_note-17">&#91;17&#93;</a></sup>)
</td>
<td><a href="/wiki/File:Swish.svg" class="image" title="Swish Activation Function"><img alt="Swish Activation Function" src="//upload.wikimedia.org/wikipedia/commons/thumb/1/12/Swish.svg/120px-Swish.svg.png" decoding="async" width="120" height="72" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/1/12/Swish.svg/180px-Swish.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/1/12/Swish.svg/240px-Swish.svg.png 2x" data-file-width="1000" data-file-height="600" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {x}{1+e^{-x}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mi>x</mi>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {x}{1+e^{-x}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/623852d52f9dc328d4168d79f470a3c3186730f6" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.171ex; width:8.374ex; height:5.009ex;" alt="{\displaystyle {\frac {x}{1+e^{-x}}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {1+e^{-x}+xe^{-x}}{\left(1+e^{-x}\right)^{2}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mn>1</mn>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>+</mo>
              <mi>x</mi>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mo>&#x2212;<!-- − --></mo>
                  <mi>x</mi>
                </mrow>
              </msup>
            </mrow>
            <msup>
              <mrow>
                <mo>(</mo>
                <mrow>
                  <mn>1</mn>
                  <mo>+</mo>
                  <msup>
                    <mi>e</mi>
                    <mrow class="MJX-TeXAtom-ORD">
                      <mo>&#x2212;<!-- − --></mo>
                      <mi>x</mi>
                    </mrow>
                  </msup>
                </mrow>
                <mo>)</mo>
              </mrow>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msup>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {1+e^{-x}+xe^{-x}}{\left(1+e^{-x}\right)^{2}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/01a6a4b826d59685162b5312f5172f985169a170" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -3.171ex; width:16.078ex; height:6.843ex;" alt="{\displaystyle {\frac {1+e^{-x}+xe^{-x}}{\left(1+e^{-x}\right)^{2}}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle [-0.278\ldots ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">[</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>0.278</mn>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle [-0.278\ldots ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/958ab90852b76ffe763b61fd8aae0a4175ea25f1" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:15.511ex; height:2.843ex;" alt="{\displaystyle [-0.278\ldots ,\infty )}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td>Mish 
<td>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle x\tanh(\ln(1+e^{x}))}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mi>x</mi>
        <mi>tanh</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mi>ln</mi>
        <mo>&#x2061;<!-- ⁡ --></mo>
        <mo stretchy="false">(</mo>
        <mn>1</mn>
        <mo>+</mo>
        <msup>
          <mi>e</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi>x</mi>
          </mrow>
        </msup>
        <mo stretchy="false">)</mo>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle x\tanh(\ln(1+e^{x}))}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e30109e9cceea5f6b732bdd7251be21201b10f4f" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:18.186ex; height:2.843ex;" alt="{\displaystyle x\tanh(\ln(1+e^{x}))}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle {\frac {(e^{x}(4e^{2x}+e^{3x}+4(1+x)+e^{x}(6+4x)))}{(2+2e^{x}+e^{2x})^{2}}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mrow class="MJX-TeXAtom-ORD">
          <mfrac>
            <mrow>
              <mo stretchy="false">(</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo stretchy="false">(</mo>
              <mn>4</mn>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>3</mn>
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>+</mo>
              <mn>4</mn>
              <mo stretchy="false">(</mo>
              <mn>1</mn>
              <mo>+</mo>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo stretchy="false">(</mo>
              <mn>6</mn>
              <mo>+</mo>
              <mn>4</mn>
              <mi>x</mi>
              <mo stretchy="false">)</mo>
              <mo stretchy="false">)</mo>
              <mo stretchy="false">)</mo>
            </mrow>
            <mrow>
              <mo stretchy="false">(</mo>
              <mn>2</mn>
              <mo>+</mo>
              <mn>2</mn>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mi>x</mi>
                </mrow>
              </msup>
              <mo>+</mo>
              <msup>
                <mi>e</mi>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                  <mi>x</mi>
                </mrow>
              </msup>
              <msup>
                <mo stretchy="false">)</mo>
                <mrow class="MJX-TeXAtom-ORD">
                  <mn>2</mn>
                </mrow>
              </msup>
            </mrow>
          </mfrac>
        </mrow>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle {\frac {(e^{x}(4e^{2x}+e^{3x}+4(1+x)+e^{x}(6+4x)))}{(2+2e^{x}+e^{2x})^{2}}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/04af231bb225292d9229140240a7f7ae9e14dd53" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -2.671ex; width:41.415ex; height:6.676ex;" alt="{\displaystyle {\frac {(e^{x}(4e^{2x}+e^{3x}+4(1+x)+e^{x}(6+4x)))}{(2+2e^{x}+e^{2x})^{2}}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle [-0.308\ldots ,\infty )}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">[</mo>
        <mo>&#x2212;<!-- − --></mo>
        <mn>0.308</mn>
        <mo>&#x2026;<!-- … --></mo>
        <mo>,</mo>
        <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
        <mo stretchy="false">)</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle [-0.308\ldots ,\infty )}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/e82abe83a0dfe1b7eb7d9c57c59f814c8e440d83" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:15.511ex; height:2.843ex;" alt="{\displaystyle [-0.308\ldots ,\infty )}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr>
<tr>
<td><a href="/wiki/Gaussian_function" title="Gaussian function">Gaussian</a>
</td>
<td><a href="/wiki/File:Activation_gaussian.svg" class="image"><img alt="Activation gaussian.svg" src="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_gaussian.svg/120px-Activation_gaussian.svg.png" decoding="async" width="120" height="60" srcset="//upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_gaussian.svg/180px-Activation_gaussian.svg.png 1.5x, //upload.wikimedia.org/wikipedia/commons/thumb/f/fe/Activation_gaussian.svg/240px-Activation_gaussian.svg.png 2x" data-file-width="120" data-file-height="60" /></a>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle e^{-x^{2}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>e</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <msup>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msup>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle e^{-x^{2}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/da5decb0035215bdd45d3d40b4b2c3a158d00fc8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:4.366ex; height:3.009ex;" alt="e^{-x^{2}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle -2xe^{-x^{2}}}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo>&#x2212;<!-- − --></mo>
        <mn>2</mn>
        <mi>x</mi>
        <msup>
          <mi>e</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mo>&#x2212;<!-- − --></mo>
            <msup>
              <mi>x</mi>
              <mrow class="MJX-TeXAtom-ORD">
                <mn>2</mn>
              </mrow>
            </msup>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle -2xe^{-x^{2}}}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7da9606f8917a9a4d2120b139dd111ab6031157e" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.505ex; width:8.666ex; height:3.176ex;" alt="{\displaystyle -2xe^{-x^{2}}}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle (0,1]}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <mo stretchy="false">(</mo>
        <mn>0</mn>
        <mo>,</mo>
        <mn>1</mn>
        <mo stretchy="false">]</mo>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle (0,1]}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/7e70f9c241f9faa8e9fdda2e8b238e288807d7a4" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.838ex; width:4.91ex; height:2.843ex;" alt="{\displaystyle (0,1]}"/></span>
</td>
<td><span class="mwe-math-element"><span class="mwe-math-mathml-inline mwe-math-mathml-a11y" style="display: none;"><math xmlns="http://www.w3.org/1998/Math/MathML"  alttext="{\displaystyle C^{\infty }}">
  <semantics>
    <mrow class="MJX-TeXAtom-ORD">
      <mstyle displaystyle="true" scriptlevel="0">
        <msup>
          <mi>C</mi>
          <mrow class="MJX-TeXAtom-ORD">
            <mi mathvariant="normal">&#x221E;<!-- ∞ --></mi>
          </mrow>
        </msup>
      </mstyle>
    </mrow>
    <annotation encoding="application/x-tex">{\displaystyle C^{\infty }}</annotation>
  </semantics>
</math></span><img src="https://wikimedia.org/api/rest_v1/media/math/render/svg/971ed05871d69309df32efdfd2020128c9cf69d8" class="mwe-math-fallback-image-inline" aria-hidden="true" style="vertical-align: -0.338ex; width:3.673ex; height:2.343ex;" alt="C^{\infty }"/></span>
</td></tr></tbody></table>
</section>
</section>
</section>
<section id="span-style-color-4361ee-referencias-span">
<h2><span style="color:#4361EE">Referencias</span><a class="headerlink" href="#span-style-color-4361ee-referencias-span" title="Enlazar permanentemente con este título">#</a></h2>
<ol class="simple">
<li><p><a class="reference external" href="https://dustinstansbury.github.io/theclevermachine/derivation-backpropagation">https://dustinstansbury.github.io/theclevermachine/derivation-backpropagation</a></p></li>
<li><p><a class="reference external" href="https://en.wikipedia.org/wiki/Activation_function">https://en.wikipedia.org/wiki/Activation_function</a></p></li>
<li><p><a class="reference external" href="https://www.geeksforgeeks.org/activation-functions-neural-networks/">https://www.geeksforgeeks.org/activation-functions-neural-networks/</a></p></li>
<li><p><a class="reference external" href="https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0">https://medium.com/the-theory-of-everything/understanding-activation-functions-in-neural-networks-9491262884e0</a></p></li>
<li><p><a class="reference external" href="https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/">https://machinelearningmastery.com/rectified-linear-activation-function-for-deep-learning-neural-networks/</a></p></li>
</ol>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "AprendizajeProfundo/Libro-Fundamentos",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            kernelName: "python3",
            path: "./Redes_Neuronales\Cuadernos"
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

              </div>
              
            </main>
            <footer class="footer-article noprint">
                
    <!-- Previous / next buttons -->
<div class='prev-next-area'>
    <a class='left-prev' id="prev-link" href="RedesNeuronales_intro.html" title="anterior página">
        <i class="fas fa-angle-left"></i>
        <div class="prev-next-info">
            <p class="prev-next-subtitle">anterior</p>
            <p class="prev-next-title"><span style="color:#F72585">Introducción a Redes Neuronales</span></p>
        </div>
    </a>
    <a class='right-next' id="next-link" href="Hello_World_ML.html" title="siguiente página">
    <div class="prev-next-info">
        <p class="prev-next-subtitle">siguiente</p>
        <p class="prev-next-title"><span style="color:#F72585">Introducción a Keras Sequential y API Funcional</span></p>
    </div>
    <i class="fas fa-angle-right"></i>
    </a>
</div>
            </footer>
        </div>
    </div>
    <div class="footer-content row">
        <footer class="col footer"><p>
  
    By Álvaro Mauricio Montenegro Díaz, Daniel Mauricio Montenegro Reyes<br/>
  
      &copy; Copyright 2022.<br/>
</p>
        </footer>
    </div>
    
</div>


      </div>
    </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../_static/scripts/pydata-sphinx-theme.js?digest=1999514e3f237ded88cf"></script>


  </body>
</html>