Traceback (most recent call last):
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\jupyter_cache\executors\utils.py", line 51, in single_nb_execution
    executenb(
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\client.py", line 1204, in execute
    return NotebookClient(nb=nb, resources=resources, km=km, **kwargs).execute()
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\util.py", line 84, in wrapped
    return just_run(coro(*args, **kwargs))
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\util.py", line 62, in just_run
    return loop.run_until_complete(coro)
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\asyncio\base_events.py", line 642, in run_until_complete
    return future.result()
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\client.py", line 663, in async_execute
    await self.async_execute_cell(
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\client.py", line 965, in async_execute_cell
    await self._check_raise_for_error(cell, cell_index, exec_reply)
  File "C:\Users\User\AppData\Local\Programs\Python\Python39\lib\site-packages\nbclient\client.py", line 862, in _check_raise_for_error
    raise CellExecutionError.from_cell_and_msg(cell, exec_reply_content)
nbclient.exceptions.CellExecutionError: An error occurred while executing the following cell:
------------------
loss.backward()
------------------

[1;31m---------------------------------------------------------------------------[0m
[1;31mRuntimeError[0m                              Traceback (most recent call last)
Input [1;32mIn [5][0m, in [0;36m<cell line: 1>[1;34m()[0m
[1;32m----> 1[0m [43mloss[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[43m)[49m

File [1;32m~\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\_tensor.py:307[0m, in [0;36mTensor.backward[1;34m(self, gradient, retain_graph, create_graph, inputs)[0m
[0;32m    298[0m [38;5;28;01mif[39;00m has_torch_function_unary([38;5;28mself[39m):
[0;32m    299[0m     [38;5;28;01mreturn[39;00m handle_torch_function(
[0;32m    300[0m         Tensor[38;5;241m.[39mbackward,
[0;32m    301[0m         ([38;5;28mself[39m,),
[1;32m   (...)[0m
[0;32m    305[0m         create_graph[38;5;241m=[39mcreate_graph,
[0;32m    306[0m         inputs[38;5;241m=[39minputs)
[1;32m--> 307[0m [43mtorch[49m[38;5;241;43m.[39;49m[43mautograd[49m[38;5;241;43m.[39;49m[43mbackward[49m[43m([49m[38;5;28;43mself[39;49m[43m,[49m[43m [49m[43mgradient[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[38;5;241;43m=[39;49m[43minputs[49m[43m)[49m

File [1;32m~\AppData\Local\Programs\Python\Python39\lib\site-packages\torch\autograd\__init__.py:154[0m, in [0;36mbackward[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)[0m
[0;32m    151[0m [38;5;28;01mif[39;00m retain_graph [38;5;129;01mis[39;00m [38;5;28;01mNone[39;00m:
[0;32m    152[0m     retain_graph [38;5;241m=[39m create_graph
[1;32m--> 154[0m [43mVariable[49m[38;5;241;43m.[39;49m[43m_execution_engine[49m[38;5;241;43m.[39;49m[43mrun_backward[49m[43m([49m
[0;32m    155[0m [43m    [49m[43mtensors[49m[43m,[49m[43m [49m[43mgrad_tensors_[49m[43m,[49m[43m [49m[43mretain_graph[49m[43m,[49m[43m [49m[43mcreate_graph[49m[43m,[49m[43m [49m[43minputs[49m[43m,[49m
[0;32m    156[0m [43m    [49m[43mallow_unreachable[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m,[49m[43m [49m[43maccumulate_grad[49m[38;5;241;43m=[39;49m[38;5;28;43;01mTrue[39;49;00m[43m)[49m

[1;31mRuntimeError[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.
RuntimeError: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.

